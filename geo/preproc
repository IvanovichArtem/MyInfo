{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40eeb085",
   "metadata": {},
   "source": [
    "1. дополнить дата сет сделками августа\n",
    "2. привязать курс доллара ко всем датам сделок\n",
    "3. при наличии пустых ячеек со стоимостью рассчитать стоимость каждого объекта во всех валютах (Есть небольшое кол-во сделок, где не указана «цена в долларах США». Надо провести следующие действия, если есть стоимость в белорусских рублях, то ее необходимо по курсу на дату сделки перевести в доллары. Курсы валют ранее направляла) Где нет стоимости есть информация в поле \"Описание цены\", можно оттуда взять стоимость.\n",
    "4. Выделить дата сет (грязный) со следующим признакам:\n",
    "\n",
    "- столбец AU (маркеры) - доля;\n",
    "- столбец AC (переходящая доля), все доли за исключением 1/1; 1/1, 1/1; 1/1, 1/1,1/1 и пустых ячеек.\n",
    "- столбец R (Количество объектов в сделке) более 1, то есть начиная с 2,3,4.....и т.д.\n",
    "- столбец AU (маркеры) - комплекс\n",
    "- столбец U (описание цены включает слова \"долей, доля,доли и т.д.\")\n",
    "- столбец U (описание цены включает слова \"Цена указана за ......... объектов\")\n",
    "\n",
    "5.  В грязном датасете распределить доли:\n",
    "    Правило:\n",
    "    столбец D (Инвентарный номер) должны совпадать, столбец АС (Переходящая доля) не равна 1/1; 1/1, 1/1; 1/1, 1/1, 1/1 и не пустая, то применяются следующие правила.\n",
    "\n",
    "    5.1 Стоимость не приводится к доле 1, если в описании цены написано \"стоимость за весь объект, за все помещение, здание и т.д.\"\n",
    "    Например,столбец АС Переходящая доля 3/4, 1/4, 3/4, 1/4, столбец D (Инвентарный номер) совпадает и в описании цены указано общая стоимость, значит стоимость не подлежит распределению.\n",
    "    Найти такие объекты и проставить отличительный знак для них для того чтобы включить в чистый дата сет. Например, 1.\n",
    "\n",
    "    5.2 Стоимость приводится к 1, если в описании цены указано стоимость X/X доли.\n",
    "    Например, столбец АС Переходящая доля 3/5, 3/5, столбец D (Инвентарный номер) совпадает и в столбец U (Описание цены) указано \"стоимость X/X долей........\" проводим увеличение стоимости до полной доли.\n",
    "    Найти такие объекты и проставить отличительный знак для них для того чтобы включить в чистый дата сет. Например,2.\n",
    "\n",
    "    5.3 Стоимость долей объединяется, если описание цены пустое, столбец D (Инвентарный номер) совпадает, столбец S (Цена в бел. руб.) разные, Переходящая доля равна в сумме 1. После объединения стоимости в бел руб, стоимость необходимо перевести в 3 валюты.\n",
    "    Например, столбец АС Переходящая доля 1/4, 3/4, столбец D (Инвентарный номер) 500/D-7110374.\n",
    "    Найти такие объекты и проставить отличительный знак для них для того чтобы включить в чистый дата сет. Например,3.\n",
    "\n",
    "    5.4 Стоимость долей не приводится, если столбец D (Инвентарный номер) совпадает, в столбец U (Описание цены) ничего не написано, столбец S (Цена в бел. руб.) одинаковые.\n",
    "    Найти такие объекты и проставить отличительный знак для них для того чтобы включить в чистый дата сет. Например,4.\n",
    "\n",
    "    Эти правила должны закрыть большую часть.\n",
    "    После разбора по этим правилам, то что останется я изучу и смогу сказать есть ли еще правила.\n",
    "\n",
    "6.  В грязном датасете распределить стоимость комплексов (AU (маркеры) - комплекс), столбец АС (Переходящая доля) равна 1/1; 1/1, 1/1; 1/1, 1/1, 1/1 и пустая.\n",
    "    Удаляем строки с полным совпадением.\n",
    "\n",
    "    6.1. Столбец Q Идентификатор сделки совпадает, столбец S (Цена в бел. руб.) одинаковый, в столбец U (Описание цены) написано, что это стоимость общая за все объекты или стоимость и перечислены капитальные строения и т.д., то проводится распределение стоимости пропорционально площади объектов в сделке.\n",
    "    Найти такие объекты и проставить отличительный знак для них для того чтобы включить в чистый дата сет. Например,5.\n",
    "\n",
    "    6.2. Столбец Q Идентификатор сделки совпадает, столбец S (Цена в бел. руб.) стоимость разная и в столбце столбец U (Описание цены) ничего не указано, стоимость не распределяется.\n",
    "    Найти такие объекты и проставить отличительный знак для них для того чтобы включить в чистый дата сет. Например,6.\n",
    "\n",
    "Чистый дата сет столбец AU (Цена содержит НДС, с НДС), необходимо уменьшить стоимость на 20%.\n",
    "Чистый дата сет столбец U (Описание цены) если написано, что включен НДС, то его надо исключить из стоимости. (например, с НДС, в т.ч. НДС, в том числе с НДС и пр.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f66924-dce8-4952-8061-462cdd495982",
   "metadata": {},
   "source": [
    "# Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d343b6c0-a362-4b56-9d75-e4cbc362d046",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import regex as re\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebce4aec",
   "metadata": {},
   "source": [
    "# Utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae2658c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_excel_df_2(\n",
    "    path,\n",
    "    sheet_name,\n",
    "    usecols=None,\n",
    "    skiprows=None,\n",
    "    additional_parse=False,\n",
    "    can_be_empty=False,\n",
    "):\n",
    "\n",
    "    df = pd.read_excel(\n",
    "        path, sheet_name=sheet_name, usecols=usecols, skiprows=skiprows\n",
    "    )\n",
    "\n",
    "    break_row = None\n",
    "    for i in range(10, len(df)):\n",
    "        if pd.isna(df.iloc[i, 0]) and pd.notna(df.iloc[i + 1, 0]):\n",
    "            break_row = i\n",
    "            break\n",
    "    if break_row is None or break_row + 1 >= len(df):\n",
    "        if can_be_empty is False:\n",
    "            raise ValueError(\"Table not found\")\n",
    "        else:\n",
    "            print(f\"Таблица для sheet={sheet_name} по пути {path} пустая\")\n",
    "\n",
    "    if additional_parse:\n",
    "        search_cond = \"not def\"\n",
    "        for i in range(0, 20):\n",
    "            full_str = df.iloc[i, 0]\n",
    "            if isinstance(full_str, str) and (\"Назначение: \" in full_str):\n",
    "                search_cond = full_str.partition(\"Назначение: \")[2]\n",
    "\n",
    "    # Заголовки — строка после пустой\n",
    "    # костыль для новых данных\n",
    "    if sheet_name in [\"Стоимость КС_РХ\", \"Выгрузка по ЗУ\"]:\n",
    "        header_row = 4\n",
    "        # print(df.iloc[header_row].values)\n",
    "    else:\n",
    "        header_row = break_row + 1\n",
    "\n",
    "    headers = df.iloc[header_row].values\n",
    "\n",
    "    # # Данные — начиная со следующей строки\n",
    "    table_data = df.iloc[header_row + 1 :].copy()\n",
    "    table_data.columns = headers\n",
    "    table_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Костыль\n",
    "    if sheet_name == \"РБ азартные\":\n",
    "        table_data = table_data.iloc[:-1, pd.notna(table_data.columns)]\n",
    "\n",
    "    if additional_parse:\n",
    "        return table_data, search_cond\n",
    "    else:\n",
    "        return table_data\n",
    "\n",
    "\n",
    "def collect_all_df(path, sheet_name=None):\n",
    "\n",
    "    excel_file = pd.ExcelFile(path)\n",
    "    sheet_names = excel_file.sheet_names if sheet_name is None else [sheet_name]\n",
    "    print(f\"Number of sheets: {len(sheet_names)}\\n\", sheet_names)\n",
    "\n",
    "    all_df = []\n",
    "\n",
    "    for sheet in sheet_names:\n",
    "        df, search_param = parse_excel_df_2(path, sheet, additional_parse=True)\n",
    "        df.rename(\n",
    "            columns={\n",
    "                \"Площадь, кв.м\": \"Общая площадь, кв.м\",\n",
    "                \"Площадь КС\": \"Общая площадь КС, кв.м\",\n",
    "                \"Этажность КС\": \"Количество надземных этажей, шт.\",\n",
    "                \"Подземная этажность КС\": \"Количество подземных этажей, шт.\",\n",
    "                \"Доп. Объекты\": \"Составные элементы и принадлежности\",\n",
    "            },\n",
    "            inplace=True,\n",
    "        )\n",
    "        if \"objectnumber\" in df.columns:\n",
    "            df.drop(columns=[\"objectnumber\"], inplace=True)\n",
    "        df[\"sheet_source\"] = sheet\n",
    "        df[\"search_param\"] = search_param\n",
    "        all_df.append(df)\n",
    "    all_df = pd.concat(all_df)\n",
    "    print(f\"df output shape: {all_df.shape}\")\n",
    "    print(f\"Num of undefined columns: {sum(pd.isna(all_df.columns))}\")\n",
    "    return all_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa0786b",
   "metadata": {},
   "source": [
    "# Working\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c579d52d",
   "metadata": {},
   "source": [
    "## Загружаем датасет\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ba9549-6471-47de-acce-e23fc0fcfbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df = pd.read_excel(\"./data/total_df.xlsx\").drop(\n",
    "    columns=[\"Unnamed: 0\", \"п/п\"]\n",
    ")\n",
    "total_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a705e0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df[\"Маркеры\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c03708-5395-4499-ad6a-560d1a31b98c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8352287e-0458-4215-a9fd-9354dc09f368",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_df.isna().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0978bbd0",
   "metadata": {},
   "source": [
    "## 1. Дополняем датасет сделками августа\n",
    "\n",
    "В файлах есть 3 листа:\n",
    "\n",
    "- `Выгрузка по КСиИП` - основной лист, оттуда будем загружать все (_header_ таблицы на 27ой строке)\n",
    "- `Стоимость КС_РХ` - лист, где по **Инвентарный номер** и **Дата сделки**\n",
    "  заберем инфу по фиче **Стоимость КС_РХ**, остальные фичи с этого листа уже присутствуют в `Выгрузка по КСиИП` (_header_ таблицы на 5ой строке)\n",
    "- `Выгрузка по ЗУ` - вся инфа с этого листа уже присутствует в `Выгрузка по КСиИП` и в основном листы пустые (_header_ таблицы на 5ой строке)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d32abc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_aug_data = \"./data/Выгрузка/\"\n",
    "new_aug_files = [\n",
    "    f\"{path_to_aug_data}{file}\" for file in os.listdir(path_to_aug_data)\n",
    "]\n",
    "new_aug_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b6c541",
   "metadata": {},
   "source": [
    "В файлах выгрузки могут быть пустые таблицы\n",
    "Лист **Выгрузка по КСиИП** основной\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b7b143",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df[total_df[\"Стоимости КС / РХ\"].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8d5954",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = pd.DataFrame()\n",
    "\n",
    "for file in new_aug_files:\n",
    "    new_df = collect_all_df(file, sheet_name=\"Выгрузка по КСиИП\")\n",
    "    cost_df = pd.read_excel(file, sheet_name=\"Стоимость КС_РХ\", header=5)\n",
    "\n",
    "    # берём колонку стоимости с листа Стоимость КС_РХ (имя может отличаться)\n",
    "    src_cost_col = (\n",
    "        \"Стоимости КС / РХ\"\n",
    "        if \"Стоимости КС / РХ\" in cost_df.columns\n",
    "        else \"Стоимость, руб. КС / РХ\"\n",
    "    )\n",
    "\n",
    "    # мерж по Инв+Дата сделки, подтягиваем новую стоимость\n",
    "    new_df = new_df.merge(\n",
    "        cost_df[[\"Инвентарный номер\", \"Дата сделки\", src_cost_col]].rename(\n",
    "            columns={src_cost_col: \"_new_cost\"}\n",
    "        ),\n",
    "        on=[\"Инвентарный номер\", \"Дата сделки\"],\n",
    "        how=\"left\",\n",
    "    )\n",
    "\n",
    "    # перезаписываем только там, где в cost_df есть значение\n",
    "    new_df[\"Стоимости КС / РХ\"] = new_df[\"_new_cost\"].where(\n",
    "        new_df[\"_new_cost\"].notna(), new_df[\"Стоимости КС / РХ\"]\n",
    "    )\n",
    "    new_df = new_df.drop(columns=[\"_new_cost\"])\n",
    "    tmp_df = pd.concat([tmp_df, new_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffeea972",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4146ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(total_df.columns) - set(tmp_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ffb3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df = pd.concat([total_df, tmp_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa82117",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df.drop(columns=[\"п/п\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456965be-089f-4327-b6f1-a13ce725d4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(total_df.duplicated().sum())\n",
    "total_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56988c8",
   "metadata": {},
   "source": [
    "# Убираем дубликаты\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3636d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "dupl_transact_price = total_df.duplicated(\n",
    "    subset=[\n",
    "        \"Инвентарный номер\",\n",
    "        \"Идентификатор сделки\",\n",
    "        \"Цена в бел. руб.\",\n",
    "        \"Цена в долларах США\",\n",
    "        \"Цена в евро\",\n",
    "        \"Цена по договору\",\n",
    "    ],\n",
    "    keep=False,\n",
    ").sum()\n",
    "dupl_transact = total_df.duplicated(\n",
    "    subset=[\"Инвентарный номер\", \"Идентификатор сделки\"], keep=False\n",
    ")\n",
    "\n",
    "print(\"Total df size: \", total_df.shape)\n",
    "print(\n",
    "    \"Total count of duplicate rows with ['Инвентарный номер', 'Идентификатор сделки', 'Цена в бел. руб.', 'Цена в долларах США', 'Цена в евро', 'Цена по договору']\",\n",
    "    dupl_transact_price.sum(),\n",
    ")\n",
    "print(\n",
    "    \"Total count of duplicate rows with ['Инвентарный номер', 'Идентификатор сделки']\",\n",
    "    dupl_transact.sum(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839b2e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Дубликаты по Инвентарный номер', 'Идентификатор сделки', по с разной ценой\n",
    "dupl_diff_price = (\n",
    "    total_df[\n",
    "        total_df[\"Идентификатор сделки\"].isin(\n",
    "            total_df[(dupl_transact != dupl_transact_price)][\n",
    "                \"Идентификатор сделки\"\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    "    .drop_duplicates(\n",
    "        subset=[\n",
    "            \"Инвентарный номер\",\n",
    "            \"Идентификатор сделки\",\n",
    "            \"Цена в бел. руб.\",\n",
    "            \"Цена в долларах США\",\n",
    "            \"Цена в евро\",\n",
    "            \"Цена по договору\",\n",
    "        ],\n",
    "        keep=\"first\",\n",
    "    )\n",
    "    .sort_values(by=\"Инвентарный номер\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2727b83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dupl_diff_price.sort_values(\n",
    "    by=[\"Идентификатор сделки\", \"Инвентарный номер\"]\n",
    ").head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258d8aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# удалим дубли + уберем варианты с одинаковыми ун идентификаторами, но разными ценами\n",
    "print(f\"Удаляем дубликаты, изн кол-во {total_df.shape}\")\n",
    "ids_with_diff_price = dupl_diff_price[\"Идентификатор сделки\"].values\n",
    "total_df_tmp = total_df[\n",
    "    total_df[\"Идентификатор сделки\"].isin(ids_with_diff_price)\n",
    "].copy()\n",
    "print(\"Кол-во после удаления дублей с разными ценами\", total_df_tmp.shape)\n",
    "total_df_tmp = total_df_tmp.drop_duplicates(\n",
    "    subset=[\"Идентификатор сделки\", \"Инвентарный номер\"], keep=\"first\"\n",
    ")\n",
    "print(\"Кол-во после удаления дубликатов\", total_df_tmp.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f438b1a",
   "metadata": {},
   "source": [
    "второй кейс, удаляем инфу где одинаковые ун ид, но разная цена. Была проблема, что продажа была долей. Бизнес подготовил выгрузку с пересчитанными ценами\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e132a5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_share = \"data/dupl_diff_price_remain.xlsx\"\n",
    "df_add_share = pd.read_excel(path_share)\n",
    "df_add_share.info()\n",
    "\n",
    "print(set(total_df_tmp.columns) - set(df_add_share.columns))\n",
    "print(set(df_add_share.columns) - set(total_df_tmp.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35de3b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape before concat\", total_df_tmp.shape)\n",
    "total_df_tmp = pd.concat([total_df_tmp, df_add_share], ignore_index=True)\n",
    "print(\"Shape after concat\", total_df_tmp.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244844c9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e840459a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"-Удлаяем продажи между родственниками, продажи по оценочной стоимости, аффилированные продажи\"\n",
    ")\n",
    "print(\n",
    "    \"количество удаленных: \",\n",
    "    sum(\n",
    "        total_df_tmp[\"Маркеры\"].str.contains(\n",
    "            \"оценочн|родственник|аффилированн\", na=False\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "print(\n",
    "    total_df_tmp[\"Маркеры\"]\n",
    "    .value_counts()\n",
    "    .loc[lambda x: x.index.str.contains(\"оценочн|родственник|аффилированн\")],\n",
    "    \"\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ea8035",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-Удлаяем продажи законсервированные\")\n",
    "print(\n",
    "    \"количество удаленных: \",\n",
    "    sum(total_df_tmp[\"Наименование КС\"].str.contains(\"законсервир\", na=False)),\n",
    ")\n",
    "print(\n",
    "    total_df_tmp[\"Наименование КС\"]\n",
    "    .value_counts()\n",
    "    .loc[lambda x: x.index.str.contains(\"законсервир\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a57fcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter = (\n",
    "    ~total_df_tmp[\"Маркеры\"].str.contains(\n",
    "        \"оценочн|родственник|аффилированн\", na=False\n",
    "    )\n",
    ") & (~total_df_tmp[\"Наименование КС\"].str.contains(\"законсервир\", na=False))\n",
    "total_df_wd_filter = total_df_tmp[filter]\n",
    "\n",
    "print(\n",
    "    \"\\nNumber of filtered rows: \",\n",
    "    len(total_df_tmp) - len(total_df_wd_filter),\n",
    "    \"\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8da3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "building = (\n",
    "    total_df_wd_filter[\"Назначение\"].str.lower().str.contains(\"сооружение\")\n",
    ")\n",
    "print(\n",
    "    'Удаляем сделки, где \"Наименование\" == \"сооружение\". Кол-во удаленных: ',\n",
    "    sum(building),\n",
    "    \"\\n\",\n",
    ")\n",
    "total_df_wd_filter = total_df_wd_filter.loc[~building]\n",
    "\n",
    "not_finished = (\n",
    "    total_df_wd_filter[\"Инвентарный номер\"].str.lower().str.contains(\"u\")\n",
    ")\n",
    "print(\n",
    "    \"Удаляем сделки, где здания не достроены. Кол-во удаленных: \",\n",
    "    sum(not_finished),\n",
    "    \"\\n\",\n",
    ")\n",
    "total_df_wd_filter = total_df_wd_filter.loc[~not_finished]\n",
    "\n",
    "total_df_wd_filter = total_df_wd_filter.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd258c1",
   "metadata": {},
   "source": [
    "## Категоризация\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489850dd",
   "metadata": {},
   "source": [
    "Выделяем этаж\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efed1d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "\n",
    "\n",
    "def floor_parsing(x):\n",
    "    if isinstance(x, str):\n",
    "        match = re.search(r\"(\\d+)\", x)\n",
    "        if match:\n",
    "            number = int(match.group(1))\n",
    "            if \"подземный\" in x.lower():\n",
    "                number = -number\n",
    "            return number\n",
    "        else:\n",
    "            return None\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2c817e",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df_wd_filter[\"floor\"] = total_df_wd_filter[\"Этаж расположения ИП\"].map(\n",
    "    floor_parsing\n",
    ")\n",
    "total_df_wd_filter.loc[\n",
    "    total_df_wd_filter[\"Этаж расположения ИП\"].isin(\n",
    "        [\"Мансардный (мансарда)\", \"Чердак\", \"Технический чердак\", \"Антресоль\"]\n",
    "    ),\n",
    "    \"floor\",\n",
    "] = total_df_wd_filter.loc[\n",
    "    total_df_wd_filter[\"Этаж расположения ИП\"].isin(\n",
    "        [\"Мансардный (мансарда)\", \"Чердак\", \"Технический чердак\", \"Антресоль\"]\n",
    "    ),\n",
    "    \"Количество надземных этажей, шт.\",\n",
    "]\n",
    "total_df_wd_filter.loc[\n",
    "    total_df_wd_filter[\"Этаж расположения ИП\"].isin([\"Подвальный\"]), \"floor\"\n",
    "] = -1\n",
    "total_df_wd_filter.loc[\n",
    "    total_df_wd_filter[\"Этаж расположения ИП\"].isin([\"Цокольный\"]), \"floor\"\n",
    "] = -0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e85c3b",
   "metadata": {},
   "source": [
    "##### **Категоризируем**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ee1f67",
   "metadata": {},
   "source": [
    "удаляем сделки с \"Назначениями\", определенными бизнесом для удаления\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743044b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подвязка логики категоризации, определенной бизнесом\n",
    "path_categories = \"data/Рапределение_назначений_281072025.xlsx\"\n",
    "df_categories_purpose = pd.read_excel(path_categories, sheet_name=\"purpose\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d338a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_categories_purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5eacd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "del_purpose = df_categories_purpose.loc[\n",
    "    df_categories_purpose[\"Категория\"] == \"удалить\", \"Назначение\"\n",
    "].values\n",
    "print(\n",
    "    'Удаление \"Назначений\", определенных бизнесом: ',\n",
    "    sum(total_df_wd_filter[\"Назначение\"].isin(del_purpose)),\n",
    "    \"\\n\",\n",
    ")\n",
    "total_df_wd_filter = total_df_wd_filter[\n",
    "    ~total_df_wd_filter[\"Назначение\"].isin(del_purpose)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a9669a",
   "metadata": {},
   "source": [
    "Маппим кейсов без доп. условий по \"Назначение\" (лист purpose)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcfdb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "offices_purpose = (\n",
    "    df_categories_purpose.loc[df_categories_purpose[\"Категория\"] == \"офис\"][\n",
    "        \"Назначение\"\n",
    "    ]\n",
    "    .str.lower()\n",
    "    .values\n",
    ")\n",
    "industry_purpose = (\n",
    "    df_categories_purpose.loc[\n",
    "        df_categories_purpose[\"Категория\"] == \"производство\"\n",
    "    ][\"Назначение\"]\n",
    "    .str.lower()\n",
    "    .values\n",
    ")\n",
    "trade_purpose = (\n",
    "    df_categories_purpose.loc[df_categories_purpose[\"Категория\"] == \"торговля\"][\n",
    "        \"Назначение\"\n",
    "    ]\n",
    "    .str.lower()\n",
    "    .values\n",
    ")\n",
    "warehouse_purpose = (\n",
    "    df_categories_purpose.loc[df_categories_purpose[\"Категория\"] == \"склад\"][\n",
    "        \"Назначение\"\n",
    "    ]\n",
    "    .str.lower()\n",
    "    .values\n",
    ")\n",
    "agriculture_purpose = (\n",
    "    df_categories_purpose.loc[df_categories_purpose[\"Категория\"] == \"сельхоз\"][\n",
    "        \"Назначение\"\n",
    "    ]\n",
    "    .str.lower()\n",
    "    .values\n",
    ")\n",
    "cto_purpose = (\n",
    "    df_categories_purpose.loc[\n",
    "        df_categories_purpose[\"Категория\"].str.lower() == \"сто\"\n",
    "    ][\"Назначение\"]\n",
    "    .str.lower()\n",
    "    .values\n",
    ")\n",
    "\n",
    "\n",
    "# Основная часть по назначениюё\n",
    "total_df_wd_filter[\"category\"] = None\n",
    "total_df_wd_filter.loc[\n",
    "    total_df_wd_filter[\"Назначение\"].str.lower().isin(agriculture_purpose),\n",
    "    \"category\",\n",
    "] = \"сельхоз\"\n",
    "total_df_wd_filter.loc[\n",
    "    total_df_wd_filter[\"Назначение\"].str.lower().isin(warehouse_purpose),\n",
    "    \"category\",\n",
    "] = \"склад\"\n",
    "total_df_wd_filter.loc[\n",
    "    total_df_wd_filter[\"Назначение\"].str.lower().isin(trade_purpose), \"category\"\n",
    "] = \"торговля\"\n",
    "total_df_wd_filter.loc[\n",
    "    total_df_wd_filter[\"Назначение\"].str.lower().isin(industry_purpose),\n",
    "    \"category\",\n",
    "] = \"производство\"\n",
    "total_df_wd_filter.loc[\n",
    "    total_df_wd_filter[\"Назначение\"].str.lower().isin(offices_purpose),\n",
    "    \"category\",\n",
    "] = \"офис\"\n",
    "total_df_wd_filter.loc[\n",
    "    total_df_wd_filter[\"Назначение\"].str.lower().isin(cto_purpose), \"category\"\n",
    "] = \"сто\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117507b7",
   "metadata": {},
   "source": [
    "Маппим кейсы, требующие условия по \"Наименование\" (определены серым цветом на вкладке 'puspose')  \n",
    "Примечание: сделано вручную. В дальнейшем требуется все это оптимизировать (как вариант вынести все такие \"Назначения\" на отдельные вкладки с указанием к чему какие \"НАименования\" относятся)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1554fe3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Аптека\n",
    "print(\n",
    "    \"помещение здравоохранения-------------------------------------------------------\"\n",
    ")\n",
    "filter_0 = (\n",
    "    total_df_wd_filter[\"Назначение\"].str.lower() == \"помещение здравоохранения\"\n",
    ") & (\n",
    "    ~total_df_wd_filter[\"Наименование\"]\n",
    "    .str.lower()\n",
    "    .isin([\"аптека\", \"аптечный киоск\"])\n",
    ")\n",
    "total_df_wd_filter.loc[filter_0, \"category\"] = \"офис\"\n",
    "\n",
    "filter_1 = (\n",
    "    total_df_wd_filter[\"Назначение\"].str.lower() == \"помещение здравоохранения\"\n",
    ") & (\n",
    "    total_df_wd_filter[\"Наименование\"]\n",
    "    .str.lower()\n",
    "    .isin([\"аптека\", \"аптечный киоск\"])\n",
    ")\n",
    "total_df_wd_filter.loc[filter_1, \"category\"] = \"торговля\"\n",
    "print(\"Total cnt: \", sum(filter_0) + sum(filter_1), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87da258d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Здание специализированное для производства строительных материалов-------------------------------------------------------\"\n",
    ")\n",
    "exclude = [\n",
    "    \"узел\",\n",
    "    \"узла\",\n",
    "    \"РБУ\",\n",
    "    \"компрессорная\",\n",
    "    \"галерея\",\n",
    "    \"смесительная\",\n",
    "    \"проходная\",\n",
    "    \"кпп\",\n",
    "    \"пристройка\",\n",
    "    \"сушилка\",\n",
    "]\n",
    "pattern = \"|\".join(map(re.escape, exclude))\n",
    "\n",
    "filter_0 = (\n",
    "    total_df_wd_filter[\"Назначение\"].str.lower()\n",
    "    == \"здание специализированное для производства строительных материалов\"\n",
    ") & (\n",
    "    ~total_df_wd_filter[\"Наименование\"].str.contains(\n",
    "        pattern, case=False, na=False\n",
    "    )\n",
    ")\n",
    "total_df_wd_filter.loc[filter_0, \"category\"] = \"производство\"\n",
    "print(\"Total cnt: \", sum(filter_0), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42357cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Помещение бытового обслуживания населения-------------------------------------------------------\"\n",
    ")\n",
    "exclude = [\"мастерск\", \"производст\"]\n",
    "pattern = \"|\".join(map(re.escape, exclude))\n",
    "\n",
    "filter_0 = (\n",
    "    total_df_wd_filter[\"Назначение\"].str.lower()\n",
    "    == \"помещение бытового обслуживания населения\"\n",
    ") & (\n",
    "    ~total_df_wd_filter[\"Наименование\"].str.contains(\n",
    "        pattern, case=False, na=False\n",
    "    )\n",
    ")\n",
    "total_df_wd_filter.loc[filter_0, \"category\"] = \"офис\"\n",
    "print(\"Total cnt: \", sum(filter_0), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be7825b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"помещение, не относящееся к жилищному фонду-------------------------------------------------------\"\n",
    ")\n",
    "include_0 = [\"мастерск\"]\n",
    "include_1 = [\"павильон\"]\n",
    "include_2 = [\"склад\"]\n",
    "\n",
    "pattern_0 = \"|\".join(map(re.escape, include_0))\n",
    "pattern_1 = \"|\".join(map(re.escape, include_1))\n",
    "pattern_2 = \"|\".join(map(re.escape, include_2))\n",
    "\n",
    "\n",
    "filter_0 = (\n",
    "    total_df_wd_filter[\"Назначение\"].str.lower()\n",
    "    == \"помещение, не относящееся к жилищному фонду\"\n",
    ") & (\n",
    "    total_df_wd_filter[\"Наименование\"].str.contains(\n",
    "        pattern_0, case=False, na=False\n",
    "    )\n",
    ")\n",
    "filter_1 = (\n",
    "    total_df_wd_filter[\"Назначение\"].str.lower()\n",
    "    == \"помещение, не относящееся к жилищному фонду\"\n",
    ") & (\n",
    "    total_df_wd_filter[\"Наименование\"].str.contains(\n",
    "        pattern_1, case=False, na=False\n",
    "    )\n",
    ")\n",
    "filter_2 = (\n",
    "    total_df_wd_filter[\"Назначение\"].str.lower()\n",
    "    == \"помещение, не относящееся к жилищному фонду\"\n",
    ") & (\n",
    "    total_df_wd_filter[\"Наименование\"].str.contains(\n",
    "        pattern_2, case=False, na=False\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "total_df_wd_filter.loc[filter_0, \"category\"] = \"производство\"\n",
    "total_df_wd_filter.loc[filter_1, \"category\"] = \"торговля\"\n",
    "total_df_wd_filter.loc[filter_2, \"category\"] = \"склад\"\n",
    "\n",
    "print(\"Total cnt: \", sum(filter_0) + sum(filter_1) + sum(filter_2), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ec5237",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Здание специализированное для производства машин и оборудования (машиностроения)-------------------------------------------------------\"\n",
    ")\n",
    "exclude = [\"Насосн\"]  # насосная станция\n",
    "pattern = \"|\".join(map(re.escape, exclude))\n",
    "\n",
    "filter_0 = (\n",
    "    total_df_wd_filter[\"Назначение\"].str.lower()\n",
    "    == \"здание специализированное для производства машин и оборудования (машиностроения)\"\n",
    ") & (\n",
    "    ~total_df_wd_filter[\"Наименование\"].str.contains(\n",
    "        pattern, case=False, na=False\n",
    "    )\n",
    ")\n",
    "total_df_wd_filter.loc[filter_0, \"category\"] = \"производство\"\n",
    "print(\"Total cnt: \", sum(filter_0), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3cfdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"здание специализированное для производства транспортных средств и оборудования-------------------------------------------------------\"\n",
    ")\n",
    "exclude = [\"азс\"]  # насосная станция\n",
    "pattern = \"|\".join(map(re.escape, exclude))\n",
    "\n",
    "filter_0 = (\n",
    "    total_df_wd_filter[\"Назначение\"].str.lower()\n",
    "    == \"здание специализированное для производства транспортных средств и оборудования\"\n",
    ") & (\n",
    "    ~total_df_wd_filter[\"Наименование\"].str.contains(\n",
    "        pattern, case=False, na=False\n",
    "    )\n",
    ")\n",
    "total_df_wd_filter.loc[filter_0, \"category\"] = \"производство\"\n",
    "print(\"Total cnt: \", sum(filter_0), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd8cfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"здание специализированное лесохозяйственного назначения-------------------------------------------------------\"\n",
    ")\n",
    "exclude = [\"склад\"]  # насосная станция\n",
    "pattern = \"|\".join(map(re.escape, exclude))\n",
    "\n",
    "filter_0 = (\n",
    "    total_df_wd_filter[\"Назначение\"].str.lower()\n",
    "    == \"здание специализированное лесохозяйственного назначения\"\n",
    ") & (\n",
    "    ~total_df_wd_filter[\"Наименование\"].str.contains(\n",
    "        pattern, case=False, na=False\n",
    "    )\n",
    ")\n",
    "filter_1 = (\n",
    "    total_df_wd_filter[\"Назначение\"].str.lower()\n",
    "    == \"здание специализированное лесохозяйственного назначения\"\n",
    ") & (\n",
    "    total_df_wd_filter[\"Наименование\"].str.contains(\n",
    "        pattern, case=False, na=False\n",
    "    )\n",
    ")\n",
    "\n",
    "total_df_wd_filter.loc[filter_0, \"category\"] = \"производство\"\n",
    "total_df_wd_filter.loc[filter_1, \"category\"] = \"склад\"\n",
    "\n",
    "print(\"Total cnt: \", sum(filter_0) + sum(filter_1), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baebe29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"помещение специализированное для ремонта и технического обслуживания автомобилей-------------------------------------------------------\"\n",
    ")\n",
    "exclude = [\"гараж\"]  # насосная станция\n",
    "pattern = \"|\".join(map(re.escape, exclude))\n",
    "\n",
    "filter_0 = (\n",
    "    total_df_wd_filter[\"Назначение\"].str.lower()\n",
    "    == \"помещение специализированное для ремонта и технического обслуживания автомобилей\"\n",
    ") & (\n",
    "    ~total_df_wd_filter[\"Наименование\"].str.contains(\n",
    "        pattern, case=False, na=False\n",
    "    )\n",
    ")\n",
    "\n",
    "total_df_wd_filter.loc[filter_0, \"category\"] = \"сто\"\n",
    "print(\"Total cnt: \", sum(filter_0), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1217f3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"здание административно-торговое-------------------------------------------------------\"\n",
    ")\n",
    "exclude = [\"магазин\", \"торг\"]  # насосная станция\n",
    "pattern = \"|\".join(map(re.escape, exclude))\n",
    "\n",
    "filter_0 = (\n",
    "    total_df_wd_filter[\"Назначение\"].str.lower()\n",
    "    == \"здание административно-торговое\"\n",
    ") & (\n",
    "    ~total_df_wd_filter[\"Наименование\"].str.contains(\n",
    "        pattern, case=False, na=False\n",
    "    )\n",
    ")\n",
    "filter_1 = (\n",
    "    total_df_wd_filter[\"Назначение\"].str.lower()\n",
    "    == \"здание административно-торговое\"\n",
    ") & (\n",
    "    total_df_wd_filter[\"Наименование\"].str.contains(\n",
    "        pattern, case=False, na=False\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "total_df_wd_filter.loc[filter_0, \"category\"] = \"офис\"\n",
    "total_df_wd_filter.loc[filter_1, \"category\"] = \"торговля\"\n",
    "\n",
    "print(\"Total cnt: \", sum(filter_0) + sum(filter_1), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033af504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отдельный кейс для азартных\n",
    "print(\n",
    "    \"здание специализированное для организации азартных игр-------------------------------------------------------\"\n",
    ")\n",
    "\n",
    "filter_0 = (\n",
    "    total_df_wd_filter[\"Назначение\"].str.lower()\n",
    "    == \"здание специализированное для организации азартных игр\"\n",
    ")\n",
    "total_df_wd_filter.loc[\n",
    "    filter_0 & (total_df_wd_filter[\"floor\"] > 1), \"category\"\n",
    "] = \"офис\"\n",
    "total_df_wd_filter.loc[\n",
    "    filter_0 & (total_df_wd_filter[\"floor\"] == 1), \"category\"\n",
    "] = \"торговля\"\n",
    "\n",
    "filter_1 = (\n",
    "    total_df_wd_filter[\"Назначение\"].str.lower()\n",
    "    == \"помещение для организации азартных игр\"\n",
    ")\n",
    "total_df_wd_filter.loc[\n",
    "    filter_1 & (total_df_wd_filter[\"floor\"] > 1), \"category\"\n",
    "] = \"офис\"\n",
    "total_df_wd_filter.loc[\n",
    "    filter_1 & (total_df_wd_filter[\"floor\"] == 1), \"category\"\n",
    "] = \"торговля\"\n",
    "\n",
    "print(\"Total cnt: \", sum(filter_0) + sum(filter_1), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54f63f3",
   "metadata": {},
   "source": [
    "Отдельная категризация тех. \"Назначений\", где дополнительно категоризируется в соответсвтии с \"Наименование\". Те кейсы, которым в маппинге для \"Наименование\" не проставлена категория, удаляются\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c787f082",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_sheet = {\n",
    "    \"Здание специализированное иного назначения\": \"специализированное иного назнач\",\n",
    "    \"Здание неустановленного назначения\": \"неустановленного назначения\",\n",
    "    \"Помещение транспортного назначения\": \"категория помещения транспорт\",\n",
    "    \"Здание специализированное для ремонта и технического обслуживания автомобилей (в том числе автомобильные заправочные и газонаполнительные станции)\": \"ремонт авто 0\",\n",
    "    \"Здание нежилое\": \"здание нежилое\",\n",
    "    \"Помещение неустановленного назначения\": \"помещение неустановлено\",\n",
    "    \"здание многофункциональное\": \"здание многофункциональное\",\n",
    "    \"Здание специализированное для ремонта и технического обслуживания автомобилей (в т.ч. автомобильные заправочные и газонаполнительные станции)\": \"ремонт авто 1\",\n",
    "    \"Помещение многофункциональное\": \"помещение многофункциональное\",\n",
    "    \"Здание специализированное для бытового обслуживания населения\": \"бытовое обслуживание\",\n",
    "    \"Здание специализированное здравоохранения и предоставления социальных услуг\": \"спец здравоохранение\",\n",
    "    \"Здание специализированное организаций оптовой торговли, материально-технического снабжения и сбыта продукции\": \"спец оптовая торговля\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f99b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "del_cnt = 0\n",
    "\n",
    "for df_key, sheet_name in name_sheet.items():\n",
    "    df = pd.read_excel(path_categories, sheet_name=sheet_name, usecols=\"A:B\")\n",
    "    df_key = df_key.lower().strip()\n",
    "    print(\"\\nChosen df: \", df_key, \"Shape: \", df.shape)\n",
    "\n",
    "    for cat in (\n",
    "        df[\"Категория\"].str.lower().value_counts(dropna=False).index.to_list()\n",
    "    ):\n",
    "        if (cat is None) or (pd.isna(cat)):\n",
    "            values = (\n",
    "                df.loc[pd.isna(df[\"Категория\"]), \"Наименование\"]\n",
    "                .str.lower()\n",
    "                .values\n",
    "            )\n",
    "            filter = (\n",
    "                pd.isna(total_df_wd_filter[\"category\"])\n",
    "                & (\n",
    "                    total_df_wd_filter[\"Назначение\"].str.lower().str.strip()\n",
    "                    == df_key\n",
    "                )\n",
    "                & (total_df_wd_filter[\"Наименование\"].str.lower().isin(values))\n",
    "            )\n",
    "            before_len = len(total_df_wd_filter)\n",
    "            total_df_wd_filter = total_df_wd_filter[~filter]\n",
    "            print(\n",
    "                f\"Num of deleted {cat}: \", len(total_df_wd_filter) - before_len\n",
    "            )\n",
    "            del_cnt += sum(filter)\n",
    "        else:\n",
    "            values = (\n",
    "                df.loc[df[\"Категория\"].str.lower() == cat, \"Наименование\"]\n",
    "                .str.lower()\n",
    "                .values\n",
    "            )\n",
    "            filter = (\n",
    "                pd.isna(total_df_wd_filter[\"category\"])\n",
    "                & (\n",
    "                    total_df_wd_filter[\"Назначение\"].str.lower().str.strip()\n",
    "                    == df_key\n",
    "                )\n",
    "                & (total_df_wd_filter[\"Наименование\"].str.lower().isin(values))\n",
    "            )\n",
    "            # filter = (total_df_wd_filter['Назначение'] == cat) & (total_df_wd_filter['Наименование'].str.lower().isin(values))\n",
    "            # filter = total_df_wd_filter['Наименование'].str.lower().isin(values)\n",
    "\n",
    "            total_df_wd_filter.loc[filter, \"category\"] = cat\n",
    "            print(f\"Num of {cat}: \", sum(filter))\n",
    "\n",
    "\n",
    "total_df_wd_filter.loc[\n",
    "    total_df_wd_filter[\"category\"] == \"прозводство\", \"category\"\n",
    "] = \"производство\"\n",
    "# Маммип в категорию 'другое', все, что не прокатегоризировалось\n",
    "# total_df_wd_filter.loc[pd.isna(total_df_wd_filter['category']), 'category'] = 'другое'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8824d2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Количество удаленных сделок по \"Назначение\": ', del_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce1ff33",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df_wd_filter[\"category\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07fc5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df_wd_filter[pd.isna(total_df_wd_filter[\"category\"])].groupby(\n",
    "    by=[\"Назначение\", \"Наименование\"], as_index=False\n",
    ").size().sort_values(\n",
    "    by=[\"Назначение\", \"size\"], ascending=[True, False]\n",
    ")  # .to_excel('uncategorized_dist.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800b1ccb",
   "metadata": {},
   "source": [
    "## Кластеризация\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a75c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# При кластеризации \"сельхоз\" & \"сто\" будем относить к группе \"склад, производство\"\n",
    "total_df_wd_filter[\"for_clusters_gr\"] = total_df_wd_filter.apply(\n",
    "    lambda row: (\n",
    "        1\n",
    "        if row[\"category\"] in [\"офис\", \"торговля\"]\n",
    "        else (\n",
    "            0\n",
    "            if row[\"category\"] in [\"склад\", \"производство\", \"сельхоз\", \"сто\"]\n",
    "            else -1\n",
    "        )\n",
    "    ),\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9982f3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils\n",
    "def extract_NP(x):\n",
    "    if \" \" in x:\n",
    "        x = x[x.find(\" \") + 1 :]\n",
    "    return x.strip()\n",
    "\n",
    "\n",
    "def match_adress(x, mapping):\n",
    "    \"Поис x в mapping\"\n",
    "\n",
    "    x = x.strip().lower().replace(\"ё\", \"е\")\n",
    "    for object in mapping:\n",
    "        if (object is not None) and (object != \"-1\"):\n",
    "            object = object.strip().lower().replace(\"ё\", \"е\")\n",
    "            match = re.search(rf\"\\b{re.escape(object)}\\b\", x)\n",
    "            if match is not None:\n",
    "                return object\n",
    "    return None\n",
    "\n",
    "\n",
    "def find_geo_object(row, clustering, target_col):\n",
    "\n",
    "    cluster = row[\"for_clusters_gr\"]\n",
    "    if cluster in [1, 0]:\n",
    "        geo = clustering.loc[\n",
    "            clustering[\"for_clusters_gr\"] == cluster, target_col\n",
    "        ]\n",
    "        address = row[\"Адрес\"]\n",
    "        matching = match_adress(address, geo)\n",
    "        return matching\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86595fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_clusters = \"./data/clusters_concat.xlsx\"\n",
    "\n",
    "df_cluster = pd.read_excel(path_clusters)\n",
    "display(df_cluster)\n",
    "df_cluster[\"Name NP\"] = df_cluster[\"Name NP\"].map(extract_NP).str.lower()\n",
    "df_cluster[\"Name region\"] = df_cluster[\"Name region\"].str.lower().str.strip()\n",
    "df_cluster[\"Name oblast\"] = df_cluster[\"Name oblast\"].str.lower().str.strip()\n",
    "\n",
    "\n",
    "df_cluster.loc[\n",
    "    (df_cluster[\"Name NP\"] == \"-\") | pd.isna(df_cluster[\"Name NP\"]), \"Name NP\"\n",
    "] = \"-1\"\n",
    "df_cluster.loc[\n",
    "    (df_cluster[\"Name region\"] == \"-\") | pd.isna(df_cluster[\"Name region\"]),\n",
    "    \"Name region\",\n",
    "] = \"-1\"\n",
    "df_cluster.loc[\n",
    "    (df_cluster[\"Name oblast\"] == \"-\") | pd.isna(df_cluster[\"Name oblast\"]),\n",
    "    \"Name oblast\",\n",
    "] = \"-1\"\n",
    "df_cluster[\"for_clusters_gr\"] = df_cluster.apply(\n",
    "    lambda row: (\n",
    "        1 if row[\"sheet_source\"] in [\"Кластеры ОД_2022 офис-торговля\"] else 0\n",
    "    ),\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5ab78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ebebc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df_wd_filter[total_df_wd_filter[\"Инвентарный номер\"] == \"500/D-7023057\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa701c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df_wd_filter[\"Name NP\"] = total_df_wd_filter.apply(\n",
    "    lambda row: find_geo_object(row, df_cluster, \"Name NP\"), axis=1\n",
    ").fillna(\"-1\")\n",
    "total_df_wd_filter[\"Name region\"] = total_df_wd_filter.apply(\n",
    "    lambda row: find_geo_object(row, df_cluster, \"Name region\"), axis=1\n",
    ").fillna(\"-1\")\n",
    "total_df_wd_filter[\"Name oblast\"] = total_df_wd_filter.apply(\n",
    "    lambda row: find_geo_object(row, df_cluster, \"Name oblast\"), axis=1\n",
    ").fillna(\"-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676d23b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df_wd_filter[total_df_wd_filter[\"Инвентарный номер\"] == \"500/D-7023057\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cb6778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определяем границы кластеров\n",
    "borders = (\n",
    "    df_cluster.loc[\n",
    "        ~(\n",
    "            (df_cluster[\"Name region\"] == \"-1\")\n",
    "            & (df_cluster[\"Name oblast\"] == \"-1\")\n",
    "        )\n",
    "    ]\n",
    "    .groupby(by=[\"Klaster\", \"for_clusters_gr\"], as_index=False)\n",
    "    .agg(min=(\"балл развития\", \"min\"), max=(\"балл развития\", \"max\"))\n",
    "    .sort_values(by=[\"for_clusters_gr\", \"min\"])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(\"Clusters borders: \")\n",
    "borders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe840d6",
   "metadata": {},
   "source": [
    "Осуществляем кластеризацию каскадом.  \n",
    "Общая логика:\n",
    "\n",
    "1. Маппим по \"населенный пункт\", \"район\", \"область\"\n",
    "2. Для неопределившихся на предыдущем шаге маппим по \"район\", \"область\" (балл берем как медиану, кластер определяем по медианному балу и границам, определенным на пред. шаге)\n",
    "3. Для неопределившихся на предыдущем шаге маппим по \"область\" (логика баллов и кластеров аналогична пред. пункту)\n",
    "4. (Костыль) для оставшихся маппим по \"населенный пункт\" (кейсы, когда указан в адресе город, но нет района/области)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c852f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выделяем кластеры с уровня \"регион-область\", 'область'\n",
    "def define_cluster(row, borders):\n",
    "    cluster = row[\"for_clusters_gr\"]\n",
    "    value = row[\"балл развития\"]\n",
    "    if cluster in [0, 1] and (value is not None):\n",
    "        borders = borders.loc[borders[\"for_clusters_gr\"] == cluster]\n",
    "        for _, rows in borders.iterrows():\n",
    "            if (value >= rows[\"min\"]) and (value <= rows[\"max\"]):\n",
    "                return rows[\"Klaster\"]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "df_cluster_region_oblast = (\n",
    "    df_cluster.loc[\n",
    "        ~(\n",
    "            (df_cluster[\"Name region\"] == \"-1\")\n",
    "            & (df_cluster[\"Name oblast\"] == \"-1\")\n",
    "        )\n",
    "    ]\n",
    "    .groupby(\n",
    "        by=[\"Name region\", \"Name oblast\", \"for_clusters_gr\"], as_index=False\n",
    "    )\n",
    "    .agg(балл_развития=(\"балл развития\", \"median\"))\n",
    "    .reset_index(drop=True)\n",
    "    .rename(columns={\"балл_развития\": \"балл развития\"})\n",
    "    .assign(\n",
    "        Klaster=lambda df: df.apply(\n",
    "            lambda row: define_cluster(row, borders), axis=1\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "df_cluster_oblast = (\n",
    "    df_cluster.loc[~(df_cluster[\"Name oblast\"] == \"-1\")]\n",
    "    .groupby(by=[\"Name oblast\", \"for_clusters_gr\"], as_index=False)\n",
    "    .agg(балл_развития=(\"балл развития\", \"median\"))\n",
    "    .reset_index(drop=True)\n",
    "    .rename(columns={\"балл_развития\": \"балл развития\"})\n",
    "    .assign(\n",
    "        Klaster=lambda df: df.apply(\n",
    "            lambda row: define_cluster(row, borders), axis=1\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# Костыль, для особых оставшихся случаев\n",
    "df_cluster_NP = df_cluster.sort_values(\n",
    "    by=[\"Name NP\", \"for_clusters_gr\", \"балл развития\"],\n",
    "    ascending=[True, True, False],\n",
    ").drop_duplicates(subset=[\"Name NP\", \"for_clusters_gr\"])[\n",
    "    [\"Name NP\", \"for_clusters_gr\", \"балл развития\", \"Klaster\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cbe6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_df_wd_filter.drop(columns=['Klaster_0', 'Klaster_1', 'Klaster_2', 'Klaster_3', 'балл_развития_0', 'балл_развития_1', 'балл_развития_2', 'балл_развития_3'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caefe69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df_wd_filter = (\n",
    "    total_df_wd_filter.merge(\n",
    "        df_cluster[\n",
    "            [\n",
    "                \"Name NP\",\n",
    "                \"Name region\",\n",
    "                \"Name oblast\",\n",
    "                \"балл развития\",\n",
    "                \"Klaster\",\n",
    "                \"for_clusters_gr\",\n",
    "            ]\n",
    "        ].rename(\n",
    "            columns={\"Klaster\": \"Klaster_0\", \"балл развития\": \"балл_развития_0\"}\n",
    "        ),\n",
    "        how=\"left\",\n",
    "        on=[\"Name NP\", \"Name region\", \"Name oblast\", \"for_clusters_gr\"],\n",
    "    )\n",
    "    .merge(\n",
    "        df_cluster_region_oblast[\n",
    "            [\n",
    "                \"Name region\",\n",
    "                \"Name oblast\",\n",
    "                \"балл развития\",\n",
    "                \"Klaster\",\n",
    "                \"for_clusters_gr\",\n",
    "            ]\n",
    "        ].rename(\n",
    "            columns={\"Klaster\": \"Klaster_1\", \"балл развития\": \"балл_развития_1\"}\n",
    "        ),\n",
    "        how=\"left\",\n",
    "        on=[\"Name region\", \"Name oblast\", \"for_clusters_gr\"],\n",
    "    )\n",
    "    .merge(\n",
    "        df_cluster_oblast[\n",
    "            [\"Name oblast\", \"балл развития\", \"Klaster\", \"for_clusters_gr\"]\n",
    "        ].rename(\n",
    "            columns={\"Klaster\": \"Klaster_2\", \"балл развития\": \"балл_развития_2\"}\n",
    "        ),\n",
    "        how=\"left\",\n",
    "        on=[\"Name oblast\", \"for_clusters_gr\"],\n",
    "    )\n",
    "    .merge(\n",
    "        df_cluster_NP[\n",
    "            [\"Name NP\", \"балл развития\", \"Klaster\", \"for_clusters_gr\"]\n",
    "        ].rename(\n",
    "            columns={\"Klaster\": \"Klaster_3\", \"балл развития\": \"балл_развития_3\"}\n",
    "        ),\n",
    "        how=\"left\",\n",
    "        on=[\"Name NP\", \"for_clusters_gr\"],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d4b754",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_total_score(row):\n",
    "\n",
    "    if (row[\"балл_развития_0\"] is not None) and (\n",
    "        pd.notna(row[\"балл_развития_0\"])\n",
    "    ):\n",
    "        return row[\"балл_развития_0\"]\n",
    "    elif (row[\"балл_развития_1\"] is not None) and (\n",
    "        pd.notna(row[\"балл_развития_1\"])\n",
    "    ):\n",
    "        return row[\"балл_развития_1\"]\n",
    "    elif (row[\"балл_развития_2\"] is not None) and (\n",
    "        pd.notna(row[\"балл_развития_2\"])\n",
    "    ):\n",
    "        return row[\"балл_развития_2\"]\n",
    "    elif (row[\"балл_развития_3\"] is not None) and (\n",
    "        pd.notna(row[\"балл_развития_3\"])\n",
    "    ):\n",
    "        return row[\"балл_развития_3\"]\n",
    "\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def define_total_cluster(row):\n",
    "\n",
    "    if (row[\"Klaster_0\"] is not None) and (pd.notna(row[\"Klaster_0\"])):\n",
    "        return row[\"Klaster_0\"]\n",
    "    elif (row[\"Klaster_1\"] is not None) and (pd.notna(row[\"Klaster_1\"])):\n",
    "        return row[\"Klaster_1\"]\n",
    "    elif (row[\"Klaster_2\"] is not None) and (pd.notna(row[\"Klaster_2\"])):\n",
    "        return row[\"Klaster_2\"]\n",
    "    elif (row[\"Klaster_3\"] is not None) and (pd.notna(row[\"Klaster_3\"])):\n",
    "        return row[\"Klaster_3\"]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc27c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df_wd_filter[\"cluster_score\"] = total_df_wd_filter.apply(\n",
    "    lambda row: define_total_score(row), axis=1\n",
    ")\n",
    "total_df_wd_filter[\"cluster\"] = total_df_wd_filter.apply(\n",
    "    lambda row: define_total_cluster(row), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e058c1",
   "metadata": {},
   "source": [
    "Филлим для неподвязанных кейсов -1 для скора, 'undef' для кластеров\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65d765d",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df_wd_filter[\"cluster_score\"] = total_df_wd_filter[\n",
    "    \"cluster_score\"\n",
    "].fillna(-1)\n",
    "total_df_wd_filter[\"cluster\"] = total_df_wd_filter[\"cluster\"].fillna(\"undef\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94724f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df_wd_filter[\"cluster\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b780be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Убираем промежуточные данные\n",
    "total_df_wd_filter.drop(\n",
    "    columns=[\n",
    "        \"Klaster_0\",\n",
    "        \"Klaster_1\",\n",
    "        \"Klaster_2\",\n",
    "        \"Klaster_3\",\n",
    "        \"балл_развития_0\",\n",
    "        \"балл_развития_1\",\n",
    "        \"балл_развития_2\",\n",
    "        \"балл_развития_3\",\n",
    "    ],\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f95fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df_wd_filter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e38683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_df_wd_filter.loc[(pd.isna(total_df_wd_filter['cluster'])) & (total_df_wd_filter['for_clusters_gr'] != -1)]#.shape#.loc[8709, 'Адрес']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ae9a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = total_df_wd_filter[['Адрес', 'for_clusters_gr', 'Name NP', 'Name region', 'Name oblast']]\n",
    "# data.loc[(data['Name NP'] == '-1') & (data['Name region'] == '-1') & (data['Name oblast'] == '-1') & (data['for_clusters_gr'] != -1)]#.iloc[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80ca8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# industry_df_wd_filter = total_df_wd_filter.loc[total_df_wd_filter['category'].isin(['склад', 'производство', 'сельхоз', 'сто'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0812e678",
   "metadata": {},
   "source": [
    "## Проверка на пустые значения\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f04a897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_df_wd_filter_test = total_df_wd_filter.loc[~pd.isna(total_df_wd_filter['category'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d03688",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_desc_values = [\n",
    "    total_df_wd_filter.nunique(),\n",
    "    total_df_wd_filter.isna().sum() + (total_df_wd_filter == \"\").sum(),\n",
    "    total_df_wd_filter.apply(\n",
    "        lambda x: (\n",
    "            x.value_counts(dropna=False).index[0]\n",
    "            if x.dtype == \"object\"\n",
    "            else x.min()\n",
    "        ),\n",
    "        axis=0,\n",
    "    ),\n",
    "    total_df_wd_filter.apply(\n",
    "        lambda x: (\n",
    "            x.value_counts(dropna=False).index[-1]\n",
    "            if x.dtype == \"object\"\n",
    "            else x.max()\n",
    "        ),\n",
    "        axis=0,\n",
    "    ),\n",
    "]\n",
    "\n",
    "feats_desc = pd.DataFrame(\n",
    "    {\n",
    "        \"dtype\": total_df_wd_filter.dtypes.astype(str),  # - тип данных\n",
    "        \"nunique\": feats_desc_values[0],  # - количество уникальных значений\n",
    "        \"nunique_%\": (\n",
    "            feats_desc_values[0] / total_df_wd_filter.shape[0] * 100\n",
    "        ).round(2),\n",
    "        \"Nulls\": feats_desc_values[1],  # - количество пропусков\n",
    "        \"Nulls_%\": (\n",
    "            feats_desc_values[1] / total_df_wd_filter.shape[0] * 100\n",
    "        ).round(2),\n",
    "        \"min\": feats_desc_values[2],  # - min\n",
    "        \"max\": feats_desc_values[3],  # - max\n",
    "    }\n",
    ").sort_values(\n",
    "    by=[\n",
    "        \"Nulls\",\n",
    "        \"nunique\",\n",
    "        \"dtype\",\n",
    "    ],  # - поля для сортировки\n",
    "    ascending=[False, False, False],  # - направление сортировки\n",
    ")\n",
    "feats_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97032d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df_wd_filter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58433a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df_wd_filter.to_excel(\n",
    "    \"./data/total_df_after_preproces_artem_without_dupl.xlsx\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdbc024",
   "metadata": {},
   "source": [
    "# NewTasks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d597d72",
   "metadata": {},
   "source": [
    "## Load and Additional\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddaabb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_df = pd.read_excel(\"./data/total_df_ater_preprocess_artem.xlsx\")\n",
    "\n",
    "total_df = pd.read_excel(\n",
    "    \"./data/total_df_after_preproces_artem_without_dupl.xlsx\"\n",
    ")\n",
    "\n",
    "print(total_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48aa7b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# в группу офис попали ненужные строки, сейчас поменяем группу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86f1f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df[\"category\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1521f4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_patterns = [\n",
    "    \"база отдыха\",\n",
    "    \"гостевой дом\",\n",
    "    \"гостиница\",\n",
    "    \"гостиничный комплекс\",\n",
    "    \"дом охотника\",\n",
    "    \"дом рыбака\",\n",
    "    \"дом отдыха\",\n",
    "    \"турбаза\",\n",
    "    \"деревянный домик\",\n",
    "    \"дом на озере\",\n",
    "    \"дом рубленный\",\n",
    "    \"дом общинника\",\n",
    "    \"коттедж\",\n",
    "]\n",
    "\n",
    "# Создаём единое регулярное выражение\n",
    "pattern = \"|\".join(exclude_patterns + [\"баня\", \"фок\"])\n",
    "\n",
    "# Применяем условие\n",
    "mask = (total_df[\"category\"].str.lower() == \"офис\") & (\n",
    "    total_df[\"Наименование\"].str.lower().str.contains(pattern, na=False)\n",
    ")\n",
    "\n",
    "# Заменяем category на NaN там, где условие выполнено\n",
    "total_df.loc[mask, \"category\"] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14231c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df[total_df[\"Наименование\"].str.contains(\"Баня\", case=False, na=False)][\n",
    "    [\"Наименование\", \"category\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e24246b",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df[\n",
    "    total_df[\"Наименование\"].str.contains(\"Гостевой дом\", case=False, na=False)\n",
    "][[\"Наименование\", \"category\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aace8e0",
   "metadata": {},
   "source": [
    "## 2 Привязать курс доллара к датам сделок\n",
    "\n",
    "Есть отдельная выгрзука с курсом зза период с 2014 по 2025.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f57167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(total_df['Дата сделки'].head())\n",
    "total_df[\"Дата сделки\"] = pd.to_datetime(total_df[\"Дата сделки\"], dayfirst=True)\n",
    "total_df[\"Дата сделки\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c4bca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "currency_data = pd.read_excel(\n",
    "    \"./data/2014_2025_cur_rates.xlsx\", sheet_name=\"курс\"\n",
    ")\n",
    "currency_data[\"Дата\"] = pd.to_datetime(currency_data[\"Дата\"], dayfirst=True)\n",
    "currency_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d95ed09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join по датам\n",
    "total_df_merged = total_df.merge(\n",
    "    currency_data, left_on=\"Дата сделки\", right_on=\"Дата\", how=\"left\"\n",
    ")\n",
    "print(\n",
    "    \"Проверим отсуствуют ли данные из-за left join\",\n",
    "    total_df_merged[currency_data.columns].isna().mean(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81708eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# всего 1 строка с пустой инфой по цене -> курс не взять\n",
    "total_df_merged.loc[\n",
    "    total_df_merged[\"1 Доллар США (USD)\"].isna(),\n",
    "    [\n",
    "        \"Дата\",\n",
    "        \"Дата сделки\",\n",
    "        \"Цена в бел. руб.\",\n",
    "        \"Цена в долларах США\",\n",
    "        \"Цена в евро\",\n",
    "    ],\n",
    "].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a477f5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df_merged.loc[\n",
    "    total_df_merged[\"1 Доллар США (USD)\"].isna(),\n",
    "    [\"Дата сделки\", \"Цена в бел. руб.\", \"Цена в долларах США\", \"Цена в евро\"],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e4ffe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df_merged[total_df_merged[\"1 Доллар США (USD)\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64100efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df_merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1b71f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rub = pd.to_numeric(total_df_merged[\"Цена в бел. руб.\"], errors=\"coerce\")\n",
    "usd = pd.to_numeric(\n",
    "    total_df_merged[\"Цена в долларах США\"], errors=\"coerce\"\n",
    ").replace(0, np.nan)\n",
    "\n",
    "rate_usd_by_date = (\n",
    "    rub.div(usd).groupby(total_df_merged[\"Дата сделки\"]).transform(\"max\")\n",
    ")\n",
    "\n",
    "total_df_merged[\"1 Доллар США (USD)\"] = (\n",
    "    pd.to_numeric(total_df_merged[\"1 Доллар США (USD)\"], errors=\"coerce\")\n",
    "    .fillna(rate_usd_by_date)\n",
    "    .round(4)\n",
    ")\n",
    "\n",
    "# --- EUR ---\n",
    "eur = pd.to_numeric(total_df_merged[\"Цена в евро\"], errors=\"coerce\").replace(\n",
    "    0, np.nan\n",
    ")\n",
    "\n",
    "rate_eur_by_date = (\n",
    "    rub.div(eur).groupby(total_df_merged[\"Дата сделки\"]).transform(\"max\")\n",
    ")\n",
    "\n",
    "total_df_merged[\"1 Евро (EUR)\"] = (\n",
    "    pd.to_numeric(total_df_merged[\"1 Евро (EUR)\"], errors=\"coerce\")\n",
    "    .fillna(rate_eur_by_date)\n",
    "    .round(4)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26190bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(total_df_merged[total_df_merged[\"1 Доллар США (USD)\"].isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e329e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Start\", total_df_merged.shape)\n",
    "total_df_merged = total_df_merged[\n",
    "    total_df_merged[\"Дата сделки\"] != \"2013-01-08\"\n",
    "]\n",
    "print(\"End\", total_df_merged.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2bc664",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df_merged.groupby(\"Дата сделки\")[\n",
    "    [\"1 Доллар США (USD)\", \"1 Евро (EUR)\"]\n",
    "].mean().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbdc5fa",
   "metadata": {},
   "source": [
    "## 3. При наличии пустых ячеек со стоимостью рассчитать стоимость каждого объекта во всех валютах\n",
    "\n",
    "(Есть небольшое кол-во сделок, где не указана «цена в долларах США». Надо провести следующие действия, если есть стоимость в белорусских рублях, то ее необходимо по курсу на дату сделки перевести в доллары. Курсы валют ранее направляла) Где нет стоимости есть информация в поле \"Описание цены\", можно оттуда взять стоимость.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf293a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_mask = [\n",
    "    \"Цена в бел. руб.\",\n",
    "    \"Цена в долларах США\",\n",
    "    \"1 Доллар США (USD)\",\n",
    "    \"Цена в евро\",\n",
    "    \"1 Евро (EUR)\",\n",
    "    \"Цена по договору\",\n",
    "    \"Описание цены\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00861b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df_merged[price_mask].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65206071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# цена по договору = цена в бел руб\n",
    "total_df_merged[\"Цена в бел. руб.\"] = np.where(\n",
    "    (total_df_merged[\"Цена в бел. руб.\"].isna())\n",
    "    & (total_df_merged[\"Цена по договору\"] != 0),\n",
    "    total_df_merged[\"Цена по договору\"],\n",
    "    total_df_merged[\"Цена в бел. руб.\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b218ad5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df_merged[price_mask].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befe9ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# бел рубли\n",
    "display(\n",
    "    total_df_merged[\n",
    "        (total_df_merged[\"Цена в бел. руб.\"].notna())\n",
    "        & (total_df_merged[\"Цена в долларах США\"].isna())\n",
    "    ][price_mask + [\"1 Доллар США (USD)\"]]\n",
    ")\n",
    "\n",
    "usd_mask = (\n",
    "    total_df_merged[\"Цена в бел. руб.\"].notna()\n",
    "    & total_df_merged[\"Цена в долларах США\"].isna()\n",
    ")\n",
    "eur_mask = (\n",
    "    total_df_merged[\"Цена в бел. руб.\"].notna()\n",
    "    & total_df_merged[\"Цена в евро\"].isna()\n",
    ")\n",
    "\n",
    "total_df_merged.loc[usd_mask, \"Цена в долларах США\"] = (\n",
    "    total_df_merged.loc[usd_mask, \"Цена в бел. руб.\"]\n",
    "    / total_df_merged.loc[usd_mask, \"1 Доллар США (USD)\"]\n",
    ")\n",
    "total_df_merged.loc[eur_mask, \"Цена в евро\"] = (\n",
    "    total_df_merged.loc[eur_mask, \"Цена в бел. руб.\"]\n",
    "    / total_df_merged.loc[eur_mask, \"1 Евро (EUR)\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db13dc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df_merged[price_mask].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fd8fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df_merged[\"Цена в бел. руб.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de19df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Dict, Tuple, Any, Optional\n",
    "\n",
    "\n",
    "class PriceExtractor:\n",
    "    \"\"\"\n",
    "    Настраиваемый извлекатель цен.\n",
    "    - Ищет шаблоны вида: '100 USD' / 'USD 100' / '$ 100' / '100 $'\n",
    "    - Русские варианты: '100 долларов', '100 долларов США', 'долл.', 'американских долларов'\n",
    "    - EUR: 'EUR', '€', 'евро'\n",
    "    - BYN: 'BYN', 'Br', 'бел. руб.', 'белорусских рублей', 'руб. BYN', 'руб. РБ'\n",
    "    - Опция treat_ue_as_usd, если хотите трактовать 'у.е.' как USD.\n",
    "    \"\"\"\n",
    "\n",
    "    NUM = r\"(?:\\d{1,3}(?:[ \\u00A0\\u202F]?\\d{3})+|\\d+)(?:[.,]\\d+)?\"\n",
    "\n",
    "    def __init__(self, treat_ue_as_usd: bool = True):\n",
    "        self.treat_ue_as_usd = treat_ue_as_usd\n",
    "\n",
    "        # расширено: ловит 'долларам/долларах/долларами США' и т.п.\n",
    "        usd_words = r\"(?:USD|\\$|долл?\\.?|доллар(?:[а-я]{0,6})?(?:\\s*США)?)\"\n",
    "        eur_words = r\"(?:EUR|€|евро)\"\n",
    "        byn_words_specific = (\n",
    "            r\"(?:BYN|Br|\"\n",
    "            r\"бел(?:орусск(?:ий|их)|\\.)\\s*руб(?:[а-я\\.]{0,6})?|\"\n",
    "            r\"бел\\.?\\s*руб(?:[а-я\\.]{0,6})?|\"\n",
    "            r\"руб(?:[а-я\\.]{0,6})?\\s*(?:BYN|РБ)\"\n",
    "            r\")\"\n",
    "        )\n",
    "        byn_words_plain = r\"(?:руб(?:[а-я\\.]{0,6})?|р\\.?)\"\n",
    "        byn_words = rf\"(?:{byn_words_specific}|{byn_words_plain})\"\n",
    "\n",
    "        self.currency_words: Dict[str, str] = {\n",
    "            \"USD\": usd_words,\n",
    "            \"EUR\": eur_words,\n",
    "            \"BYN\": byn_words,\n",
    "        }\n",
    "\n",
    "        # Скомпилированные паттерны: число-перед/после валюты\n",
    "        self.patterns: Dict[str, Any] = {\n",
    "            cur: [\n",
    "                re.compile(rf\"(?<!\\w)({self.NUM})\\s*(?:{words})(?!\\w)\", re.I),\n",
    "                re.compile(rf\"(?<!\\w)(?:{words})\\s*({self.NUM})(?!\\w)\", re.I),\n",
    "            ]\n",
    "            for cur, words in self.currency_words.items()\n",
    "        }\n",
    "\n",
    "        if self.treat_ue_as_usd:\n",
    "            # Очень частый кейс в СНГ: у.е. ~ USD\n",
    "            self.patterns[\"USD\"] += [\n",
    "                re.compile(\n",
    "                    rf\"(?<!\\w)({self.NUM})\\s*(?:у\\.?е\\.?|у[\\s-]?е)(?!\\w)\", re.I\n",
    "                ),\n",
    "                re.compile(\n",
    "                    rf\"(?<!\\w)(?:у\\.?е\\.?|у[\\s-]?е)\\s*({self.NUM})(?!\\w)\", re.I\n",
    "                ),\n",
    "            ]\n",
    "\n",
    "        # ---- ДОБАВЛЕНО: generic BYN (если явных валют нет) ----\n",
    "        # ловим конструкции: \"сумма/сумму/в сумме/в размере <число>\" или \"<число> сумма/цена/стоимость/итого\"\n",
    "        self.generic_byn_patterns = [\n",
    "            re.compile(\n",
    "                rf\"(?<!\\w)({self.NUM})\\s*(?:сумм[аеуы]|цена|стоимость|итог(?:о)?|в\\s*размере)(?!\\w)\",\n",
    "                re.I,\n",
    "            ),\n",
    "            re.compile(\n",
    "                rf\"(?<!\\w)(?:сумм[аеуы]|цена|стоимость|итог(?:о)?|в\\s*размере)\\s*({self.NUM})(?!\\w)\",\n",
    "                re.I,\n",
    "            ),\n",
    "            re.compile(rf\"(?<!\\w)в\\s*сумме\\s*({self.NUM})(?!\\w)\", re.I),\n",
    "        ]\n",
    "\n",
    "    @staticmethod\n",
    "    def _normalize_number(num_str: str) -> Tuple[float, str]:\n",
    "        \"\"\"\n",
    "        Приводит строку-число к float, возвращает (значение, объяснение_нормализации).\n",
    "        Учитывает неразрывные пробелы, пробелы-тысячные, запятую как десятичный разделитель.\n",
    "        \"\"\"\n",
    "        if not isinstance(num_str, str):\n",
    "            return (np.nan, \"не строка\")\n",
    "        s = num_str.strip().replace(\"\\u00a0\", \" \").replace(\"\\u202f\", \" \")\n",
    "        explain = []\n",
    "        # удалить пробелы-тысячные (между цифрами)\n",
    "        if re.search(r\"(?<=\\d) (?=\\d)\", s):\n",
    "            s = re.sub(r\"(?<=\\d) (?=\\d)\", \"\", s)\n",
    "            explain.append(\"удалены пробелы-тысячные\")\n",
    "        # если есть и запятая, и точка — считаем запятую тысячной\n",
    "        if \",\" in s and \".\" in s:\n",
    "            s = s.replace(\",\", \"\")\n",
    "            explain.append(\"удалены запятые-тысячные\")\n",
    "        elif \",\" in s and \".\" not in s:\n",
    "            s = s.replace(\",\", \".\")\n",
    "            explain.append(\"замена запятой на точку (десятичная)\")\n",
    "        # взять первое число\n",
    "        m = re.findall(r\"[+-]?\\d+(?:\\.\\d+)?\", s)\n",
    "        if not m:\n",
    "            return (np.nan, \"число не распознано\")\n",
    "        try:\n",
    "            return (\n",
    "                float(m[0]),\n",
    "                \"; \".join(explain) if explain else \"без преобразований\",\n",
    "            )\n",
    "        except Exception as e:\n",
    "            return (np.nan, f\"ошибка преобразования: {e}\")\n",
    "\n",
    "    def extract_from_text(\n",
    "        self, text: Any\n",
    "    ) -> Tuple[Dict[str, float], str, Dict[str, Optional[str]]]:\n",
    "        \"\"\"\n",
    "        Возвращает:\n",
    "        - dict значений {'USD': float|nan, 'EUR': ..., 'BYN': ...}\n",
    "        - строку-лог\n",
    "        - dict форм {'USD': matched_str|None, ...}\n",
    "        Берём ТОЛЬКО первое по позиции совпадение; generic BYN используем, если явных валют нет.\n",
    "        \"\"\"\n",
    "        vals = {\"USD\": np.nan, \"EUR\": np.nan, \"BYN\": np.nan}\n",
    "        forms: Dict[str, Optional[str]] = {\n",
    "            \"USD\": None,\n",
    "            \"EUR\": None,\n",
    "            \"BYN\": None,\n",
    "        }\n",
    "\n",
    "        if not isinstance(text, str):\n",
    "            return vals, \"исходное значение: не строка\", forms\n",
    "\n",
    "        t = text.strip()\n",
    "\n",
    "        # 1) явные валюты\n",
    "        candidates = []  # (pos, cur, value, full_match, order, note)\n",
    "        for cur, pats in self.patterns.items():\n",
    "            for i, p in enumerate(pats):\n",
    "                m = p.search(t)\n",
    "                if m:\n",
    "                    raw = m.group(1)\n",
    "                    val, norm_note = self._normalize_number(raw)\n",
    "                    order = (\n",
    "                        \"число перед валютой\"\n",
    "                        if (i % 2 == 0)\n",
    "                        else \"валюта перед числом\"\n",
    "                    )\n",
    "                    candidates.append(\n",
    "                        (m.start(), cur, val, m.group(0), order, norm_note)\n",
    "                    )\n",
    "                    break  # для этой валюты берём самый ранний матч\n",
    "\n",
    "        # 2) если явных нет — пробуем generic BYN (сумма/в сумме/в размере/цена/стоимость/итого)\n",
    "        if not candidates:\n",
    "            for p in self.generic_byn_patterns:\n",
    "                m = p.search(t)\n",
    "                if m:\n",
    "                    raw = m.group(1)\n",
    "                    val, norm_note = self._normalize_number(raw)\n",
    "                    candidates.append(\n",
    "                        (\n",
    "                            m.start(),\n",
    "                            \"BYN\",\n",
    "                            val,\n",
    "                            m.group(0),\n",
    "                            \"generic BYN\",\n",
    "                            norm_note,\n",
    "                        )\n",
    "                    )\n",
    "                    break\n",
    "\n",
    "        if not candidates:\n",
    "            # как и раньше — если ничего не нашли, пишем \"не найдено\" для каждой валюты\n",
    "            logs = [f\"{cur}: не найдено\" for cur in [\"USD\", \"EUR\", \"BYN\"]]\n",
    "            return vals, \" | \".join(logs), forms\n",
    "\n",
    "        # Берём самый ранний по позиции кандидат\n",
    "        pos, cur, val, full, order, note = sorted(\n",
    "            candidates, key=lambda x: x[0]\n",
    "        )[0]\n",
    "        vals[cur] = val\n",
    "        forms[cur] = full\n",
    "        log_used = f\"{cur}: '{full}' -> {val} ({order}; {note}); выбрано как первое совпадение\"\n",
    "\n",
    "        # Для остальных валют просто отметим, что проигнорированы (или не найдены)\n",
    "        logs = [log_used]\n",
    "        for other in [\"USD\", \"EUR\", \"BYN\"]:\n",
    "            if other == cur:\n",
    "                continue\n",
    "            if any(c[1] == other for c in candidates):\n",
    "                logs.append(\n",
    "                    f\"{other}: найдено, но проигнорировано (берём первое совпадение)\"\n",
    "                )\n",
    "            else:\n",
    "                logs.append(f\"{other}: не найдено\")\n",
    "\n",
    "        return vals, \" | \".join(logs), forms\n",
    "\n",
    "    def transform(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        col_name: str,\n",
    "        with_cases: bool = True,\n",
    "        return_copy: bool = True,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Применить к DataFrame.\n",
    "        Добавляет колонки USD/EUR/BYN, 'Логика извлечения' и (опц.) 'Форма_<CUR>'.\n",
    "        \"\"\"\n",
    "        if col_name not in df.columns:\n",
    "            raise KeyError(\n",
    "                f'В DataFrame нет колонки \"{col_name}\". Доступные: {list(df.columns)}'\n",
    "            )\n",
    "\n",
    "        target = df.copy() if return_copy else df\n",
    "        extracted = target[col_name].apply(self.extract_from_text)\n",
    "\n",
    "        vals_df = extracted.apply(lambda x: x[0]).apply(pd.Series)\n",
    "        vals_df = vals_df[[\"USD\", \"EUR\", \"BYN\"]]  # гарантируем порядок\n",
    "\n",
    "        logs = extracted.apply(lambda x: x[1])\n",
    "        forms_df = extracted.apply(lambda x: x[2]).apply(pd.Series)\n",
    "        forms_df.columns = [f\"Форма_{c}\" for c in forms_df.columns]\n",
    "\n",
    "        target[[\"USD\", \"EUR\", \"BYN\"]] = vals_df\n",
    "        target[\"Логика извлечения\"] = logs\n",
    "        if with_cases:\n",
    "            for c in [\"USD\", \"EUR\", \"BYN\"]:\n",
    "                target[f\"Форма_{c}\"] = forms_df.get(f\"Форма_{c}\")\n",
    "\n",
    "        return target\n",
    "\n",
    "    @staticmethod\n",
    "    def collect_unique_forms(transformed_df: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Собирает витрину уникальных найденных форм по валютам.\n",
    "        \"\"\"\n",
    "        rows = []\n",
    "        for cur in [\"USD\", \"EUR\", \"BYN\"]:\n",
    "            col = f\"Форма_{cur}\"\n",
    "            if col in transformed_df.columns:\n",
    "                uniq = (\n",
    "                    transformed_df[col]\n",
    "                    .dropna()\n",
    "                    .astype(str)\n",
    "                    .drop_duplicates()\n",
    "                    .tolist()\n",
    "                )\n",
    "                for u in uniq:\n",
    "                    rows.append({\"Валюта\": cur, \"Пример найденной формы\": u})\n",
    "        return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190df546",
   "metadata": {},
   "outputs": [],
   "source": [
    "pe = PriceExtractor(treat_ue_as_usd=True)\n",
    "res = pe.transform(total_df_merged, \"Описание цены\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc0e5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_prices_from_temp(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    mapping = {\n",
    "        \"BYN\": \"Цена в бел. руб.\",\n",
    "        \"USD\": \"Цена в долларах США\",\n",
    "        \"EUR\": \"Цена в евро\",\n",
    "    }\n",
    "    for col in mapping.values():\n",
    "        if col not in out.columns:\n",
    "            out[col] = np.nan\n",
    "    for temp_col, target_col in mapping.items():\n",
    "        if temp_col in out.columns:\n",
    "            mask = out[target_col].isna() & out[temp_col].notna()\n",
    "            out.loc[mask, target_col] = out.loc[mask, temp_col]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f34f78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df_merged = fill_prices_from_temp(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9bff73",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df_merged[price_mask].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1b333c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (\n",
    "    total_df_merged[\"Цена в бел. руб.\"].isna()\n",
    "    & total_df_merged[\"Цена в долларах США\"].notna()\n",
    ")\n",
    "\n",
    "total_df_merged.loc[usd_mask, \"Цена в бел. руб.\"] = (\n",
    "    total_df_merged.loc[usd_mask, \"Цена в долларах США\"]\n",
    "    * total_df_merged.loc[usd_mask, \"1 Доллар США (USD)\"]\n",
    ")\n",
    "total_df_merged[price_mask].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ab83f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df_merged[\"Цена в бел. руб.\"] = (\n",
    "    total_df_merged[\"Цена в долларах США\"]\n",
    "    * total_df_merged[\"1 Доллар США (USD)\"]\n",
    ")\n",
    "total_df_merged[\"Цена в евро\"] = (\n",
    "    total_df_merged[\"Цена в бел. руб.\"] / total_df_merged[\"1 Евро (EUR)\"]\n",
    ")\n",
    "total_df_merged[price_mask].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ab01fa",
   "metadata": {},
   "source": [
    "остальное не достать или нету инфы\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f205b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df_merged = total_df_merged[total_df_merged[\"Цена в бел. руб.\"].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae636283",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df_merged[price_mask].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8566391a",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667e147b",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df_merged.to_excel(\"./data/total_df_with_curr.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1671aacb",
   "metadata": {},
   "source": [
    "## 4. Выделить дата сет (грязный) со следующим признакам:\n",
    "\n",
    "- столбец AU (маркеры) - доля;\n",
    "- столбец AC (переходящая доля), все доли за исключением 1/1; 1/1, 1/1; 1/1, 1/1,1/1 и пустых ячеек.\n",
    "- столбец R (Количество объектов в сделке) более 1, то есть начиная с 2,3,4.....и т.д.\n",
    "- столбец AU (маркеры) - комплекс\n",
    "- столбец U (описание цены включает слова \"долей, доля,доли и т.д.\")\n",
    "- столбец U (описание цены включает слова \"Цена указана за ......... объектов\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7507fc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df_merged = pd.read_excel(\"./data/total_df_with_curr.xlsx\")\n",
    "filtered_df = total_df_merged.copy()\n",
    "filtered_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7bf024",
   "metadata": {},
   "source": [
    "Количество объектов в сделке $> 1$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6a1871",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_with_two_and_more = filtered_df[\n",
    "    filtered_df[\"Количество объектов в сделке\"] > 1\n",
    "].index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8177f908",
   "metadata": {},
   "source": [
    "**Описание цены** включает в себя\n",
    "\n",
    "- слова доля и тд\n",
    "- Включает слова `Цена указана за `\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e12aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "re_dolya = r\"(?i)(?<!\\w)(доля|доли|долей|долю|доле|долям|долях|долями)(?!\\w)\"\n",
    "mask_dolya = pd.Series(False, index=filtered_df.index)\n",
    "mask_dolya = (\n",
    "    filtered_df[\"Описание цены\"].astype(str).str.contains(re_dolya, na=False)\n",
    ")\n",
    "idx_dolya_U = filtered_df.index[mask_dolya].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01d0db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_lower = filtered_df[\"Описание цены\"].astype(str).str.lower()\n",
    "mask_price_starts = u_lower.str.match(\n",
    "    r\"(?u)^\\s*цена\\s*указана\\s*за\\b[^,\\.;\\n\\r]*\\bобъект(?:а|у|ом|е|ы|ов|ам|ами|ах)?\\b\",\n",
    "    na=False,\n",
    ")\n",
    "idx_price_starts = filtered_df.index[mask_price_starts].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fead4a",
   "metadata": {},
   "source": [
    "Маркеры - доля и Маркеры - комплекс\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34dbd5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_dolya = filtered_df[\"Маркеры\"].astype(str).str.contains(re_dolya, na=False)\n",
    "idx_dolya_AU = filtered_df.index[mask_dolya].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1055a5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "re_complex = r\"(?i)(?<!\\w)(комплекс|комплекса|комплексу|комплексом|комплексе|комплексы|комплексов|комплексам|комплексами|комплексах)(?!\\w)\"\n",
    "\n",
    "mask_complex = (\n",
    "    filtered_df[\"Маркеры\"].astype(str).str.contains(re_complex, na=False)\n",
    ")\n",
    "idx_complex = filtered_df.index[mask_complex].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e1fa1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.loc[idx_complex, \"Маркеры\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066aa649",
   "metadata": {},
   "source": [
    "Переходящая доля\n",
    "for word in filtered_df['Переходящая доля'].unique():\n",
    "print(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5dd548",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in filtered_df[\"Переходящая доля\"].unique():\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992e9ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_allowed_fractions = [\"1/1\", \"1/1, 1/1\", \"1/1, 1/1, 1/1\", pd.NA]\n",
    "idx_without_1_1 = filtered_df[\n",
    "    (~filtered_df[\"Переходящая доля\"].isin(not_allowed_fractions))\n",
    "    & (filtered_df[\"Переходящая доля\"].notna())\n",
    "].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd8415c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187c0e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Собираем в список в нужном порядке\n",
    "idx_list = [\n",
    "    idx_dolya_AU,  # 1) столбец AU (маркеры) - доля\n",
    "    idx_without_1_1,  # 2) столбец AC (переходящая доля) — все, кроме 1/1; 1/1,1/1; 1/1,1/1,1/1 и пустых\n",
    "    idx_with_two_and_more,  # 3) столбец R (кол-во объектов) >= 2\n",
    "    idx_complex,  # 4) столбец AU (маркеры) - комплекс\n",
    "    idx_dolya_U,  # 5) столбец U (описание цены включает \"доля/долей/доли …\")\n",
    "    idx_price_starts,  # 6) столбец U (\"Цена указана за ... объектов\")\n",
    "]\n",
    "\n",
    "sheet_names = [\n",
    "    \"AU маркеры — доля\",\n",
    "    \"AC переходящая — исключ.\",\n",
    "    \"R кол-во ≥ 2\",\n",
    "    \"AU маркеры — комплекс\",\n",
    "    \"U описание — доля\",\n",
    "    \"U описание — цена указана\",\n",
    "]\n",
    "\n",
    "\n",
    "# ====== ПОМОЩНИК: безопасно получить ДФ по списку индексов ======\n",
    "def df_from_idx(df: pd.DataFrame, idxs) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Возвращает срез df по меткам индекса из idxs.\n",
    "    - Тихо игнорирует отсутствующие метки (пересечение с df.index).\n",
    "    - Сбрасывает индекс (без колонки индекса).\n",
    "    \"\"\"\n",
    "    if idxs is None:\n",
    "        return df.head(0).copy()\n",
    "    keep = df.index.intersection(pd.Index(idxs))\n",
    "    return df.loc[keep].reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Собираем датафреймы для каждого листа\n",
    "dfs_per_sheet = [df_from_idx(filtered_df, x) for x in idx_list]\n",
    "\n",
    "# ====== ЗАПИСЬ В EXCEL ======\n",
    "out_path = \"./data/выгрузка_6_листов_4_задача_v2.xlsx\"\n",
    "with pd.ExcelWriter(out_path, engine=\"xlsxwriter\") as writer:\n",
    "    for sheet_df, name in zip(dfs_per_sheet, sheet_names):\n",
    "        safe_name = name[:31]\n",
    "        sheet_df.to_excel(writer, index=False, sheet_name=safe_name)\n",
    "\n",
    "print(f\"OK → {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ceec36",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_any = pd.Series(False, index=filtered_df.index)\n",
    "\n",
    "for idx in idx_list:\n",
    "    if isinstance(idx, (pd.Series, np.ndarray)) and (\n",
    "        (isinstance(idx, pd.Series) and idx.dtype == bool)\n",
    "        or (isinstance(idx, np.ndarray) and idx.dtype == bool)\n",
    "    ):\n",
    "        cur = pd.Series(\n",
    "            idx,\n",
    "            index=(\n",
    "                filtered_df.index\n",
    "                if not isinstance(idx, pd.Series)\n",
    "                else idx.index\n",
    "            ),\n",
    "        )\n",
    "        cur = cur.reindex(filtered_df.index, fill_value=False).astype(bool)\n",
    "        mask_any |= cur\n",
    "\n",
    "    # Иначе считаем, что это индекс-подмножество строк (метки или позиции)\n",
    "    else:\n",
    "        cur = filtered_df.index.isin(pd.Index(idx))\n",
    "        mask_any |= cur\n",
    "\n",
    "# Единый датасет по правилу \"хотя бы одно условие истинно\"\n",
    "filtered_df = filtered_df.loc[mask_any].copy()\n",
    "\n",
    "print(\"filtered_df:\", filtered_df.shape, \"=> combined (OR):\", filtered_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c221ff01",
   "metadata": {},
   "source": [
    "## 5. В грязном датасете распределить доли:\n",
    "\n",
    "Правило:\n",
    "столбец D (Инвентарный номер) должны совпадать, столбец АС (Переходящая доля) не равна 1/1; 1/1, 1/1; 1/1, 1/1, 1/1 и не пустая, то применяются следующие правила.\n",
    "\n",
    "5.1 Стоимость не приводится к доле 1, если в описании цены написано \"стоимость за весь объект, за все помещение, здание и т.д.\"\n",
    "Например,столбец АС Переходящая доля 3/4, 1/4, 3/4, 1/4, столбец D (Инвентарный номер) совпадает и в описании цены указано общая стоимость, значит стоимость не подлежит распределению.\n",
    "Найти такие объекты и проставить отличительный знак для них для того чтобы включить в чистый дата сет. Например, 1.\n",
    "\n",
    "5.2 Стоимость приводится к 1, если в описании цены указано стоимость X/X доли.\n",
    "Например, столбец АС Переходящая доля 3/5, 3/5, столбец D (Инвентарный номер) совпадает и в столбец U (Описание цены) указано \"стоимость X/X долей........\" проводим увеличение стоимости до полной доли.\n",
    "Найти такие объекты и проставить отличительный знак для них для того чтобы включить в чистый дата сет. Например,2.\n",
    "\n",
    "5.3 Стоимость долей объединяется, если описание цены пустое, столбец D (Инвентарный номер) совпадает, столбец S (Цена в бел. руб.) разные, Переходящая доля равна в сумме 1. После объединения стоимости в бел руб, стоимость необходимо перевести в 3 валюты.\n",
    "Например, столбец АС Переходящая доля 1/4, 3/4, столбец D (Инвентарный номер) 500/D-7110374.\n",
    "Найти такие объекты и проставить отличительный знак для них для того чтобы включить в чистый дата сет. Например,3.\n",
    "\n",
    "5.4 Стоимость долей не приводится, если столбец D (Инвентарный номер) совпадает, в столбец U (Описание цены) ничего не написано, столбец S (Цена в бел. руб.) одинаковые.\n",
    "Найти такие объекты и проставить отличительный знак для них для того чтобы включить в чистый дата сет. Например,4.\n",
    "\n",
    "Эти правила должны закрыть большую часть.\n",
    "После разбора по этим правилам, то что останется я изучу и смогу сказать есть ли еще правила.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b9db99",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df_merged = pd.read_excel(\"./data/total_df_with_curr.xlsx\")\n",
    "total_df = total_df_merged.copy()\n",
    "total_df = total_df[\n",
    "    (~total_df[\"Переходящая доля\"].isin(not_allowed_fractions))\n",
    "    & (\n",
    "        total_df[\"Переходящая доля\"].notna()\n",
    "        & (total_df[\"Количество объектов в сделке\"] > 1)\n",
    "    )\n",
    "]\n",
    "# берем инв номера > 1\n",
    "total_df = total_df[total_df.duplicated(\"Инвентарный номер\", keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cd3797",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1451d483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Колонки\n",
    "# =========================\n",
    "COL_INV = \"Инвентарный номер\"  # D\n",
    "COL_SHARE = \"Переходящая доля\"  # AC\n",
    "COL_PRICE_BYN = \"Цена в бел. руб.\"  # S\n",
    "COL_DESC = \"Описание цены\"  # U\n",
    "COL_RULE = \"RULE_ID\"  # результат\n",
    "\n",
    "WRITE_MASK = [\n",
    "    COL_INV,\n",
    "    COL_SHARE,\n",
    "    COL_PRICE_BYN,\n",
    "    COL_DESC,\n",
    "    COL_RULE,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74bdbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _normalize_text(x: str) -> str:\n",
    "    \"\"\"\n",
    "    Нормализация текста: to str, lower, замена NBSP/узких пробелов,\n",
    "    схлопывание whitespace до одного пробела, trim.\n",
    "    \"\"\"\n",
    "    s = \"\" if x is None else str(x)\n",
    "    s = s.replace(\"\\u00a0\", \" \").replace(\"\\u2009\", \" \").replace(\"\\u202f\", \" \")\n",
    "    s = s.lower()\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "\n",
    "def _ensure_rule_col(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Гарантирует наличие столбца RULE_ID (строки). Не мутирует исходный df.\n",
    "    \"\"\"\n",
    "    out = df.copy()\n",
    "    if COL_RULE not in out.columns:\n",
    "        out[COL_RULE] = \"\"\n",
    "    else:\n",
    "        out[COL_RULE] = out[COL_RULE].astype(str).fillna(\"\")\n",
    "    return out\n",
    "\n",
    "\n",
    "def _assign_group_rule(\n",
    "    out: pd.DataFrame, mask_condition: pd.Series, rule_id: str\n",
    "):\n",
    "    \"\"\"\n",
    "    Назначает RULE_ID=rule_id всем строкам тех инв. групп,\n",
    "    где внутри группы есть хотя бы одна строка с mask_condition=True,\n",
    "    но только если им ещё не присвоено более приоритетное правило (COL_RULE==\"\").\n",
    "    \"\"\"\n",
    "    group_has = mask_condition.groupby(out[COL_INV]).transform(\"any\")\n",
    "    out.loc[(out[COL_RULE] == \"\") & group_has, COL_RULE] = rule_id\n",
    "\n",
    "\n",
    "def _to_number_series(x: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Приводит столбец к числовому виду (float), понимая BYN в строках с пробелами/запятыми.\n",
    "    \"\"\"\n",
    "    if np.issubdtype(x.dtype, np.number):\n",
    "        return x.astype(float)\n",
    "    return (\n",
    "        x.astype(str)\n",
    "        .str.replace(\"\\u00a0\", \"\", regex=False)\n",
    "        .str.replace(\" \", \"\", regex=False)\n",
    "        .str.replace(\",\", \".\", regex=False)\n",
    "    ).pipe(pd.to_numeric, errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a3fb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAT_SHARE_IN_DESC = re.compile(\n",
    "    r\"(?:\\b\\d+\\s*/\\s*\\d+\\b)|\\bдол(?:я|и|ей|ю|ях|ями|е|ам|\\.?)\\b\",\n",
    "    flags=re.IGNORECASE,\n",
    ")\n",
    "\n",
    "# 5.1: «за весь объект / за целое …» (расширенный шаблон + ваши фразы)\n",
    "PAT_WHOLE = re.compile(\n",
    "    r\"(?:\"\n",
    "    r\"\\bобщая\\s*стоимость\\b|\"  # общая стоимость\n",
    "    r\"(?:\\bцена|\\bстоимость)\\s*за\\s*(?:весь|всё|все)\\s*объект\\w*|\"  # цена/стоимость за весь объект\n",
    "    r\"(?:\\bцена|\\bстоимость)\\s*за\\s*(?:весь|всё|все)\\s*\"\n",
    "    r\"(?:помещени\\w*|здани\\w*|комплекс\\w*|имуществ\\w*)|\"  # за всё помещение/здание/...\n",
    "    r\"(?:\\bцена|\\bстоимость)\\s*указан[ао]?\\s*за\\s*цел\\w*\"\n",
    "    r\"(?:\\s*(?:объект\\w*|помещени\\w*|здани\\w*|комплекс\\w*|имуществ\\w*))?|\"  # цена указана за целое ...\n",
    "    r\"\\bуказан[ао]?\\s*цена\\s*за\\s*(?:весь|всё|все)\\s*объект\\w*|\"  # указана цена за весь объект\n",
    "    r\"стоимость\\s*(?:за\\s*)?(?:весь|всё|все)\\s*\"\n",
    "    r\"(?:объект|объекты|помещение|помещения|здание|здания|\"\n",
    "    r\"комплекс|имущество|капитал\\w*\\s*строен\\w*|строен\\w*|сооружен\\w*)|\"  # капитальное строение/сооружение\n",
    "    r\"стоимость\\s*(?:всего|за\\s*весь)\\s*(?:объекта|помещения|здания|комплекса|имущества)|\"\n",
    "    r\"(?:\\bсумма|\\bцена)\\s*за\\s*(?:всё|все)\\b|\"\n",
    "    r\"\\bуказан[ао]?\\s*общая\\s*сумма\\b|\"\n",
    "    r\"(?:\\bцена|\\bстоимость)\\s*указан[ао]?\\s*за\\s*\\d+\"\n",
    "    r\"(?:\\s*(?:объект(?:ов|а)?|помещени\\w*|здани\\w*|\"\n",
    "    r\"капитал\\w*\\s*(?:строен\\w*|сооружен\\w*)|комплекс\\w*|единиц\\w*))?|\"  # цена указана за N объектов/единиц\n",
    "    # добавленные формулировки (ваши списки)\n",
    "    r\"\\bуказан[ао]?\\s*стоимость\\s*целого\\s*капитал\\w*\\s*строен\\w*\\b|\"  # Указана стоимость целого капитального строения\n",
    "    r\"\\bстоимость\\s*указан[ао]?\\s*за\\s*в(?:сё|се)\\s*помещени\\w*\\b|\"  # Стоимость указана за всё помещение\n",
    "    r\"\\bстоимость\\s*целого\\s*(?:изолированн\\w*\\s*)?помещени\\w*\\b|\"  # стоимость целого (изолированного) помещения\n",
    "    r\"\\bцена\\s*указан[ао]?\\s*в\\s*отношени[ие]\\s*всего\\s*объект\\w*\\b|\"  # цена указана в отношении всего объекта\n",
    "    r\"\\bцена\\s*указан[ао]?\\s*за\\s*помещени\\w*\\b|\"  # цена указана за помещение\n",
    "    r\"\\bцена\\s*помещени\\w*\\s*по\\s*договору\\b|\"  # цена помещения по договору\n",
    "    r\"\\bцена\\s*за\\s*помещени\\w*\\s*в\\s*целом\\b|\"  # цена за помещение в целом\n",
    "    r\"\\bуказан[ао]?\\s*общая\\s*цена\\s*за\\s*капитал\\w*\\b|\"  # Указана общая цена за капитальные …\n",
    "    r\"\\bцена\\s*за\\s*целое\\s*помещени\\w*\\s*указан[ао]?\\s*согласно\\b|\"  # цена за целое помещение указана согласно\n",
    "    r\"\\bобщая\\s*сумма\\s*по\\s*договору\\s*(?:купли-?продажи)?\\b|\"  # общая сумма по договору (купли-продажи)\n",
    "    r\"\\bцена\\s*за\\s*целое\\s*(?:изолированн\\w*\\s*)?помещени\\w*\\b|\"  # цена за целое изолированное помещение\n",
    "    r\"\\bцена\\s*за\\s*целы[йе]\\s*объект\\b|\"  # цена за целый объект\n",
    "    r\"\\bуказан[ао]?\\s*цена\\s*за\\s*целое\\s*капитал\\w*\\s*строен\\w*\\b\"  # Указана цена за целое капитальное строение\n",
    "    r\")\",\n",
    "    flags=re.IGNORECASE,\n",
    ")\n",
    "\n",
    "# Фракция a/b (для 5.2, 5.3)\n",
    "_FRACTION_RE = re.compile(r\"\\b(\\d+)\\s*/\\s*(\\d+)\\b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761b77e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_rule_5_1(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = _ensure_rule_col(df)\n",
    "    desc_norm = out[COL_DESC].fillna(\"\").map(_normalize_text)\n",
    "    mask_whole = desc_norm.str.contains(\n",
    "        PAT_WHOLE\n",
    "    )  # упоминание \"за весь объект\"\n",
    "    mask_has_share = desc_norm.str.contains(\n",
    "        PAT_SHARE_IN_DESC\n",
    "    )  # есть явные упоминания доли\n",
    "    mask_rule_row = mask_whole & ~mask_has_share  # цена за целое и нет доли\n",
    "    _assign_group_rule(out, mask_rule_row, \"1\")  # приоритет по группе\n",
    "    return out\n",
    "\n",
    "\n",
    "def _extract_first_fraction_not_1(desc: str):\n",
    "    # берём первую дробь != 1/1; если нет — None\n",
    "    for m in _FRACTION_RE.finditer(desc or \"\"):\n",
    "        num = int(m.group(1))\n",
    "        den = int(m.group(2))\n",
    "        if den == 0 or num == den:\n",
    "            continue\n",
    "        return num, den, f\"{num}/{den}\"\n",
    "    return None\n",
    "\n",
    "\n",
    "def _extract_fraction_from_cost_phrase(\n",
    "    desc: str, near_limit: int = 20, max_den: int = 100000\n",
    "):\n",
    "    import re\n",
    "\n",
    "    s = (desc or \"\").lower()\n",
    "\n",
    "    # 1) Точный шаблон: \"цена указана в отношении X/X доли в праве собственности\"\n",
    "    m = re.search(\n",
    "        r\"\\bцена\\s+указана\\s+в\\s+отношени\\w*\\s+(\\d+)\\s*/\\s*(\\d+)\\s+дол[яеи]\\s+в\\s+праве\\s+собственности\\b\",\n",
    "        s,\n",
    "        flags=0,\n",
    "    )\n",
    "    if m:\n",
    "        num, den = int(m.group(1)), int(m.group(2))\n",
    "        if den != 0 and num != den and num < den and den <= max_den:\n",
    "            return num, den, f\"{num}/{den}\"\n",
    "\n",
    "    # 2) Остальные допускаемые формулировки (как раньше)\n",
    "    patterns = [\n",
    "        re.compile(\n",
    "            r\"стоимост\\w*.{0,%d}?(\\d+)\\s*/\\s*(\\d+).{0,10}?(дол[а-я]*)\"\n",
    "            % near_limit\n",
    "        ),\n",
    "        re.compile(\n",
    "            r\"стоимост\\w*.{0,%d}?(дол[а-я]*).{0,10}?(\\d+)\\s*/\\s*(\\d+)\"\n",
    "            % near_limit\n",
    "        ),\n",
    "        re.compile(\n",
    "            r\"цен\\w*.{0,10}?за.{0,%d}?(\\d+)\\s*/\\s*(\\d+)(?:.{0,10}?(дол[а-я]*))?\"\n",
    "            % near_limit\n",
    "        ),\n",
    "        re.compile(\n",
    "            r\"цен\\w*.{0,%d}?(\\d+)\\s*/\\s*(\\d+).{0,10}?(дол[а-я]*)\" % near_limit\n",
    "        ),\n",
    "        re.compile(\n",
    "            r\"\\bза.{0,%d}?(\\d+)\\s*/\\s*(\\d+).{0,10}?(дол[а-я]*)\" % near_limit\n",
    "        ),\n",
    "        re.compile(\n",
    "            r\"указан\\w*.{0,%d}?цен\\w*.{0,%d}?(\\d+)\\s*/\\s*(\\d+)(?:.{0,10}?(дол[а-я]*))?\"\n",
    "            % (near_limit, near_limit)\n",
    "        ),\n",
    "        re.compile(\n",
    "            r\"цен\\w*.{0,%d}?указан\\w*.{0,%d}?в\\s*отношени\\w*.{0,%d}?(\\d+)\\s*/\\s*(\\d+)(?:.{0,10}?(дол[а-я]*))?\"\n",
    "            % (near_limit, near_limit, near_limit)\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    def _looks_like_year_pair(a: int, b: int) -> bool:\n",
    "        return (1900 <= a <= 2099) and (1900 <= b <= 2099)\n",
    "\n",
    "    for pat in patterns:\n",
    "        m = pat.search(s)\n",
    "        if not m:\n",
    "            continue\n",
    "        nums = [int(g) for g in m.groups() if g and g.isdigit()]\n",
    "        if len(nums) < 2:\n",
    "            continue\n",
    "        num, den = nums[0], nums[1]\n",
    "        if (\n",
    "            den == 0\n",
    "            or num == den\n",
    "            or num > den\n",
    "            or den > max_den\n",
    "            or _looks_like_year_pair(num, den)\n",
    "        ):\n",
    "            continue\n",
    "        return num, den, f\"{num}/{den}\"\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def apply_rule_5_2(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = _ensure_rule_col(df).copy()\n",
    "\n",
    "    price_col = COL_PRICE_BYN\n",
    "    price_new_col = f\"{price_col}_new\"  # новая цена, приведённая к 1 доле\n",
    "    if price_new_col not in out.columns:\n",
    "        out[price_new_col] = np.nan\n",
    "\n",
    "    desc_norm = (\n",
    "        out[COL_DESC].fillna(\"\").map(_normalize_text)\n",
    "    )  # нормализация к нижнему регистру\n",
    "    price = _to_number_series(out[price_col])\n",
    "\n",
    "    # если есть \"общая стоимость\" — 5.2 НЕ применяем к этой строке\n",
    "    mask_forbid = desc_norm.str.contains(r\"\\bобщая стоимость\\b\")\n",
    "\n",
    "    has_fraction_row, new_prices = [], []\n",
    "    for s, p, forbid in zip(\n",
    "        desc_norm.tolist(), price.tolist(), mask_forbid.tolist()\n",
    "    ):\n",
    "        if forbid:\n",
    "            has_fraction_row.append(False)  # помечаем как \"не подходит для 5.2\"\n",
    "            new_prices.append(np.nan)  # новую цену не считаем\n",
    "            continue\n",
    "\n",
    "        fx = _extract_fraction_from_cost_phrase(\n",
    "            s\n",
    "        )  # ловит \"стоимость/цена ... X/X (доли)\"\n",
    "        if fx is None or pd.isna(p):\n",
    "            has_fraction_row.append(False)\n",
    "            new_prices.append(np.nan)\n",
    "        else:\n",
    "            num, den, _ = fx\n",
    "            new_prices.append(\n",
    "                p * (den / num) if num != 0 else np.nan\n",
    "            )  # приводим к полной доле\n",
    "            has_fraction_row.append(True)\n",
    "\n",
    "    out[price_new_col] = new_prices\n",
    "\n",
    "    _assign_group_rule(\n",
    "        out, pd.Series(has_fraction_row, index=out.index), \"2\"\n",
    "    )  # метка по группе (как у тебя сейчас)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def apply_rule_5_3(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = _ensure_rule_col(df).copy()\n",
    "\n",
    "    desc_norm = out[COL_DESC].fillna(\"\").map(_normalize_text)\n",
    "    desc_empty = desc_norm.eq(\"\")  # все описания пустые\n",
    "    price = _to_number_series(out[COL_PRICE_BYN])\n",
    "\n",
    "    def _sum_fractions(s: str):\n",
    "        # суммируем все дроби в ячейке вида \"1/2, 1/2\"; если нет валидных — NaN\n",
    "        if s is None:\n",
    "            return np.nan\n",
    "        text = str(s)\n",
    "        found = list(_FRACTION_RE.finditer(text))\n",
    "        if not found:\n",
    "            return np.nan\n",
    "        total = 0.0\n",
    "        for m in found:\n",
    "            num = int(m.group(1))\n",
    "            den = int(m.group(2))\n",
    "            if den == 0:\n",
    "                return np.nan\n",
    "            total += num / den\n",
    "        return total\n",
    "\n",
    "    share_sum_row = out[COL_SHARE].map(_sum_fractions)  # сумма долей в строке\n",
    "    parsed_ok_row = share_sum_row.notna()\n",
    "\n",
    "    grp = out.groupby(COL_INV)\n",
    "    group_size = grp[COL_INV].transform(\"size\")\n",
    "    mask_group_mult = group_size >= 2  # группа >= 2 строк\n",
    "\n",
    "    all_desc_empty = desc_empty.groupby(out[COL_INV]).transform(\"all\")\n",
    "    price_nunique = price.groupby(out[COL_INV]).transform(\n",
    "        lambda s: s.nunique(dropna=False)\n",
    "    )\n",
    "    diff_prices = price_nunique >= 2  # в группе >=2 уникальных цен\n",
    "\n",
    "    sum_share_group = share_sum_row.groupby(out[COL_INV]).transform(\n",
    "        \"sum\"\n",
    "    )  # сумма долей по группе\n",
    "    all_rows_parsed = parsed_ok_row.groupby(out[COL_INV]).transform(\n",
    "        \"all\"\n",
    "    )  # все строки распарсились\n",
    "    sum_is_one = (\n",
    "        sum_share_group - 1.0\n",
    "    ).abs() <= 1e-6  # сумма долей == 1 (с допуском)\n",
    "\n",
    "    mask_rule_row = (\n",
    "        mask_group_mult\n",
    "        & all_desc_empty\n",
    "        & diff_prices\n",
    "        & all_rows_parsed\n",
    "        & sum_is_one\n",
    "    )\n",
    "\n",
    "    _assign_group_rule(\n",
    "        out, mask_rule_row, \"3\"\n",
    "    )  # только метка; строки не трогаем\n",
    "    return out\n",
    "\n",
    "\n",
    "def apply_rule_5_4(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = _ensure_rule_col(df)\n",
    "\n",
    "    desc_norm = out[COL_DESC].fillna(\"\").map(_normalize_text)\n",
    "    mask_desc_empty = desc_norm.eq(\"\")\n",
    "\n",
    "    price = _to_number_series(out[COL_PRICE_BYN])\n",
    "\n",
    "    group_size = out.groupby(COL_INV)[COL_INV].transform(\"size\")\n",
    "    mask_group_mult = group_size >= 2\n",
    "\n",
    "    all_desc_empty = mask_desc_empty.groupby(out[COL_INV]).transform(\"all\")\n",
    "    price_nunique = price.groupby(out[COL_INV]).transform(\n",
    "        lambda s: s.nunique(dropna=False)\n",
    "    )\n",
    "    mask_price_equal = price_nunique.eq(1)  # во всей группе одна и та же цена\n",
    "\n",
    "    mask_rule_row = mask_group_mult & all_desc_empty & mask_price_equal\n",
    "    _assign_group_rule(out, mask_rule_row, \"4\")\n",
    "    return out\n",
    "\n",
    "\n",
    "def finalize_rules_set_zero(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = _ensure_rule_col(df).copy()\n",
    "    out[COL_RULE] = out[COL_RULE].fillna(\n",
    "        \"0\"\n",
    "    )  # для всех остальных RULE_ID = '0'\n",
    "    return out\n",
    "\n",
    "\n",
    "def apply_all_rules(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    out = apply_rule_5_1(out)  # 1\n",
    "    out = apply_rule_5_2(out)  # 2\n",
    "    out = apply_rule_5_3(out)  # 3\n",
    "    out = apply_rule_5_4(out)  # 4\n",
    "    out = finalize_rules_set_zero(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48b7f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "WRITE_MASK = [\n",
    "    COL_INV,\n",
    "    \"Дата сделки\",\n",
    "    COL_SHARE,\n",
    "    COL_PRICE_BYN,\n",
    "    COL_DESC,\n",
    "    COL_RULE,\n",
    "]\n",
    "\n",
    "\n",
    "result = apply_all_rules(total_df)\n",
    "result[WRITE_MASK].to_excel(\"rules.xlsx\", index=False)\n",
    "# либо сохранить весь df с метками:\n",
    "# result.to_excel(\"rules_all.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1256acfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask3 = result[COL_RULE].eq(\"3\")\n",
    "\n",
    "# сумма по цене внутри каждой группы ИНВ, но считаем только по строкам с RULE_ID=3\n",
    "sum_by_inv_for_rule3 = result.loc[mask3].groupby(COL_INV)[COL_PRICE_BYN].sum()\n",
    "\n",
    "# если RULE_ID=3 — подставляем групповую сумму, иначе 0\n",
    "result[f\"{COL_PRICE_BYN}_new\"] = np.where(\n",
    "    mask3,\n",
    "    result[COL_INV].map(sum_by_inv_for_rule3).fillna(0),\n",
    "    result[f\"{COL_PRICE_BYN}_new\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31de7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "result[result[\"RULE_ID\"] == \"3\"][[COL_PRICE_BYN, f\"{COL_PRICE_BYN}_new\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26476447",
   "metadata": {},
   "outputs": [],
   "source": [
    "result[COL_PRICE_BYN] = np.where(\n",
    "    result[f\"{COL_PRICE_BYN}_new\"].notna()\n",
    "    & (result[f\"{COL_PRICE_BYN}_new\"] != 0),\n",
    "    result[f\"{COL_PRICE_BYN}_new\"],\n",
    "    result[COL_PRICE_BYN],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a35ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "result[[COL_PRICE_BYN, f\"{COL_PRICE_BYN}_new\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f069758b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ac7546",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.drop(\n",
    "    columns=[\"Цена в бел. руб._new\", \"Форма_USD\", \"Форма_EUR\", \"Форма_BYN\"]\n",
    ").to_excel(\"5.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abf0666",
   "metadata": {},
   "source": [
    "## 6. В грязном датасете распределить стоимость комплексов\n",
    "\n",
    "(AU (маркеры) - комплекс), столбец АС (Переходящая доля) равна 1/1; 1/1, 1/1; 1/1, 1/1, 1/1 и пустая.\n",
    "Удаляем строки с полным совпадением.\n",
    "\n",
    "6.1. Столбец Q Идентификатор сделки совпадает, столбец S (Цена в бел. руб.) одинаковый, в столбец U (Описание цены) написано, что это стоимость общая за все объекты или стоимость и перечислены капитальные строения и т.д., то проводится распределение стоимости пропорционально площади объектов в сделке.\n",
    "Найти такие объекты и проставить отличительный знак для них для того чтобы включить в чистый дата сет. Например,5.\n",
    "\n",
    "6.2. Столбец Q Идентификатор сделки совпадает, столбец S (Цена в бел. руб.) стоимость разная и в столбце столбец U (Описание цены) ничего не указано, стоимость не распределяется.\n",
    "Найти такие объекты и проставить отличительный знак для них для того чтобы включить в чистый дата сет. Например,6.\n",
    "\n",
    "---\n",
    "\n",
    "Давайте я поясню, доля 1/1; 1/1, 1/1; 1/1, 1/1,1/1 и пустых ячеек говорит о том, что объект продавался целиком. А маркер комплекс говорит о том, что кроме этого объекта в доле 1/1; 1/1, 1/1; 1/1, 1/1,1/1 и пустых ячеек могли продаваться еще другие изолированные помещения/капитальные строения и стоимость у них могла быть общей. В зависимости от этих факторов есть два правила.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e98613a",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df_merged = pd.read_excel(\"./data/total_df_with_curr.xlsx\")\n",
    "total_df = total_df_merged.copy()\n",
    "total_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0cea79",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Start\", total_df.shape)\n",
    "total_df = total_df.loc[idx_complex]\n",
    "print(\"After complex\", total_df.shape)\n",
    "# или в 1/1 или пустое\n",
    "total_df = total_df[\n",
    "    (total_df[\"Переходящая доля\"].isin(not_allowed_fractions))\n",
    "    | (total_df[\"Переходящая доля\"].isna())\n",
    "    & (total_df[\"Количество объектов в сделке\"] > 1)\n",
    "]\n",
    "print(\"After AC\", total_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120d64e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df[\"Переходящая доля\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eaf0f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "COL_ID = \"Идентификатор сделки\"\n",
    "COL_BYN = \"Цена в бел. руб.\"\n",
    "COL_DESC = \"Описание цены\"\n",
    "COL_AREA = \"Общая площадь, кв.м\"\n",
    "total_df = total_df[\n",
    "    (total_df[COL_ID].duplicated(keep=False))\n",
    "    & (total_df[\"Количество объектов в сделке\"] > 1)\n",
    "]\n",
    "# Столбец для метки правил\n",
    "if \"rules_6\" not in total_df.columns:\n",
    "    total_df[\"rules_6\"] = 0\n",
    "else:\n",
    "    total_df[\"rules_6\"] = total_df[\"rules_6\"].fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8dd5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "PHRASES_RULE1_R = [\n",
    "    # базовые «общая ...»\n",
    "    r\"\\b(?:указан[ао]?\\s*)?(?:общая|итоговая|суммарная)\\s+цена\\b(?:\\s*(?:по\\s+договору(?:\\s+купли-?продажи)?|по\\s+сделке|сделк[ае]))?\",\n",
    "    r\"\\b(?:указан[ао]?\\s*)?(?:общая|итоговая|суммарная)\\s+сумма\\b(?:\\s*(?:по\\s+договору(?:\\s+купли-?продажи)?|по\\s+сделке|сделк[ае]))?\",\n",
    "    r\"\\b(?:указан[ао]?\\s*)?(?:общая|итоговая|суммарная)\\s+стоимость\\b(?:\\s*(?:по\\s+договору(?:\\s+купли-?продажи)?|по\\s+сделке|сделк[ае]))?\",\n",
    "    # явные короткие варианты\n",
    "    r\"\\bуказан[ао]?\\s*общая\\s*сумма\\b\",\n",
    "    r\"\\bуказан[ао]?\\s*общая\\s*стоимость\\b\",\n",
    "    r\"\\bуказан[ао]?\\s*общая\\s*цена\\b\",\n",
    "    r\"\\bОбщая\\s+сумма\\b\",  # строгое соответствие \"Общая сумма\"\n",
    "    # «общая цена объектов/капитальных строений»\n",
    "    r\"\\bобщая\\s+цена\\s+(?:объект\\w*|капиталь\\w+\\s+строени\\w*)\\b\",\n",
    "    # запрошенные дополнительные фразы\n",
    "    r\"\\bцена\\s+капитального\\s+строения\\s+с\\s+ндс\\b\",\n",
    "    r\"\\bцена\\s+продажи\\s+указана\\s+в\\s+отношении\\s+\\d+\\-\",\n",
    "    r\"\\bуказан[ао]?\\s*цена\\s+объект\\w*\\s+с\\s+инвентарн\\w+\\s+номер\\w*\\b\",\n",
    "    r\"\\bсумма\\s+указана\\s+за\\s+капитальные\\s+строения\\s+с\\s+инвентарн\\w+\\s+номер\\w*\\b\",\n",
    "    r\"\\bцена\\s+указана\\s+за\\s+\\d+\\b\",\n",
    "    r\"\\bсумма\\s+указана\\s+за\\s+все\\s+объекты\\s+недвижимости\\b\",\n",
    "    r\"\\bуказана\\s+общая\\s+стоимость\\s+объетов\\b\",\n",
    "    r\"\\bуказана\\s+общая\\s+стоимость\\s+объектов\\b\",\n",
    "    r\"\\bстоимость\\s+за\\s+\\d+\\b\",\n",
    "    r\"\\bсумма\\s+за\\s+отчуждение\\s+капитальных\\s+строений\\s+с\\s+инвентарными\\s+номерами\\b\",\n",
    "    r\"\\bцена\\s+продажи\\s+за\\s+изолированные\\s+помещения\\s+с\\s+инвентарными\\s+номерами\\b\",\n",
    "    r\"\\bцена\\s+продажи\\s+капитального\\s+строения\\b\",\n",
    "    r\"\\bцена\\s+(?:(?:пять|пяти|шесть|шести|семь|семи)|\\d+(?:\\s*[-–—]?\\s*(?:ти|и))?)\\s+капитальных\\s+строений\\b\",\n",
    "    r\"\\bцена\\s+продажи\\s+указана\\s+в\\s+отношении\\s+(?:(?:пять|пяти|шесть|шести|семь|семи)|\\d+(?:\\s*[-–—]?\\s*(?:ти|и))?)\\s+следующ(?:их|его)\\s+объект(?:ов|а)\\b\",\n",
    "    r\"\\bцена\\s+указана\\s+с\\s+уч[её]том\\s+стоимости\\s+(?:(?:\\d+(?:\\s*[-–—]?\\s*(?:ти|и))?)|одно(?:го)?|двух|тр(?:е|ё)х|четыр(?:е|ё)х|пяти|шести|семи|восьми|девяти|десяти|одиннадцати|двенадцати|тринадцати|четырнадцати|пятнадцати|шестнадцати|семнадцати|восемнадцати|девятнадцати|двадцати|тридцати|сорока|пятидесяти|шестидесяти|семидесяти|восьмидесяти|девяноста|(?:двадцати|тридцати|сорока|пятидесяти|шестидесяти|семидесяти|восьмидесяти|девяноста)\\s+(?:одного|двух|тр(?:е|ё)х|четыр(?:е|ё)х|пяти|шести|семи|восьми|девяти))\\s+капитальных\\s+строений\\s+с\\s+инвентарными\\s+номерами\\b\",\n",
    "    r\"\\b(?:цена|стоимость)\\s+указана\\s+с\\s+уч[её]том\\s+стоимости\\s+(?:(?:\\d+(?:\\s*[-–—]?\\s*(?:ти|и))?)|одно(?:го)?|двух|тр(?:е|ё)х|четыр(?:е|ё)х|пяти|шести|семи|восьми|девяти|десяти|одиннадцати|двенадцати|тринадцати|четырнадцати|пятнадцати|шестнадцати|семнадцати|восемнадцати|девятнадцати|двадцати|тридцати|сорока|пятидесяти|шестидесяти|семидесяти|восьмидесяти|девяноста|(?:двадцати|тридцати|сорока|пятидесяти|шестидесяти|семидесяти|восьмидесяти|девяноста)\\s+(?:одного|двух|тр(?:е|ё)х|четыр(?:е|ё)х|пяти|шести|семи|восьми|девяти))\\s+капитальных\\s+строений\\s+с\\s+инвентарными\\s+номерами\\b\",\n",
    "]\n",
    "\n",
    "# --- единый паттерн только из этого списка ---\n",
    "PAT_RULE1_ONLY = re.compile(\n",
    "    \"|\".join(f\"(?:{p})\" for p in PHRASES_RULE1_R),\n",
    "    flags=re.IGNORECASE | re.UNICODE,\n",
    ")\n",
    "\n",
    "\n",
    "def _is_empty_desc(x) -> bool:\n",
    "    return (pd.isna(x)) or (str(x).strip() == \"\")\n",
    "\n",
    "\n",
    "def mask_rule1(series: pd.Series) -> pd.Series:\n",
    "    \"\"\"True там, где описание содержит нужные формулировки.\"\"\"\n",
    "    return (\n",
    "        series.fillna(\"\").astype(str).str.contains(PAT_RULE1_ONLY, regex=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7283c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_col = f\"{COL_BYN}_new\"\n",
    "if new_col not in total_df.columns:\n",
    "    total_df[new_col] = pd.NA  # подготовим столбец\n",
    "\n",
    "for deal_id in total_df[COL_ID].unique():\n",
    "    seg_idx = total_df.index[total_df[COL_ID] == deal_id]\n",
    "    seg = total_df.loc[seg_idx]\n",
    "\n",
    "    prices_nunique = seg[COL_BYN].nunique(dropna=False)\n",
    "    same_price = prices_nunique == 1\n",
    "    prices_vary = prices_nunique > 1\n",
    "\n",
    "    # проверка по списку r\"\" фраз\n",
    "    any_phrase_mask = mask_rule1(seg[COL_DESC])\n",
    "\n",
    "    all_desc_empty = seg[COL_DESC].map(_is_empty_desc).all()\n",
    "    any_desc_has_phrase = any_phrase_mask.any()\n",
    "\n",
    "    # 6.1: одна цена по сделке + найдены целевые формулировки\n",
    "    if same_price and any_desc_has_phrase:\n",
    "        prices = seg[COL_BYN]\n",
    "        total_price = float(prices.iloc[0])\n",
    "\n",
    "        areas = seg[COL_AREA].values\n",
    "        area_sum = areas.sum()\n",
    "\n",
    "        alloc = (areas / area_sum) * total_price\n",
    "        total_df.loc[seg_idx, new_col] = alloc.round(2)\n",
    "        total_df.loc[seg_idx, \"rules_6\"] = 1\n",
    "\n",
    "    # 6.2: цены различаются, описания пустые — переносим исходную цену\n",
    "    elif prices_vary and all_desc_empty:\n",
    "        total_df.loc[seg_idx, new_col] = seg[COL_BYN].values\n",
    "        total_df.loc[seg_idx, \"rules_6\"] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd48168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wanted_cols = [COL_ID, COL_BYN, COL_DESC, COL_AREA, new_col, \"rules_6\"]\n",
    "# export_df = total_df[wanted_cols].sort_values(\n",
    "#     [COL_ID, \"rules_6\"], ascending=[True, False]\n",
    "# )\n",
    "\n",
    "# # путь и сохранение\n",
    "# out_path = \"rules6_result.xlsx\"\n",
    "# with pd.ExcelWriter(out_path, engine=\"openpyxl\") as writer:\n",
    "#     export_df.to_excel(writer, index=False, sheet_name=\"rules6\")\n",
    "\n",
    "# print(f\"Готово: {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4ac7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df[\"rules_6\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3930a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df[total_df[COL_ID] == \"60655494-комплекс\"][\n",
    "    [COL_ID, COL_BYN, COL_AREA, new_col, COL_DESC]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bdd656",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9897f096",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df.drop(\n",
    "    columns=[new_col, \"Форма_USD\", \"Форма_EUR\", \"Форма_BYN\"]\n",
    ").to_excel(\"6.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5789407",
   "metadata": {},
   "source": [
    "## НДС и объединение\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5533fb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df = pd.read_excel(\"./data/total_df_with_curr.xlsx\")\n",
    "df_5 = pd.read_excel(\"./5.xlsx\", index_col=0).rename(\n",
    "    {\"RULE_ID\": \"rules_5\"}, axis=1\n",
    ")\n",
    "df_6 = pd.read_excel(\"./6.xlsx\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c488f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(set(df_5) - set(total_df.columns), df_5.shape)\n",
    "print(set(df_6) - set(total_df.columns), df_6.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5737e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df[\"rules_5\"] = \"-\"\n",
    "total_df[\"rules_6\"] = \"-\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d92a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "for src, rule_col in ([df_5, \"rules_5\"], [df_6, \"rules_6\"]):\n",
    "    idx = total_df.index.intersection(src.index)\n",
    "    total_df.loc[idx, COL_BYN] = src.loc[idx, COL_BYN]\n",
    "    total_df.loc[idx, rule_col] = src.loc[idx, rule_col].fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d03ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df[\"rules_6\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3979c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df[total_df[\"rules_5\"] == \"-\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eab1aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df[\"Цена в долларах США\"] = (\n",
    "    total_df[\"Цена в бел. руб.\"] / total_df[\"1 Доллар США (USD)\"]\n",
    ")\n",
    "total_df[\"Цена в евро\"] = (\n",
    "    total_df[\"Цена в бел. руб.\"] / total_df[\"1 Евро (EUR)\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645fd8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NDS_conv(\n",
    "    df: pd.DataFrame, desc_col: str, price_cols: list[str]\n",
    ") -> pd.DataFrame:\n",
    "    # приводим описание к нижнему регистру\n",
    "    desc = df[desc_col].fillna(\"\").astype(str).str.lower()\n",
    "\n",
    "    # фразы-исключения (значит, цена уже без НДС/НДС не применяется)\n",
    "    exclude_phrases = [\n",
    "        \"без ндс\",\n",
    "        \"без учета ндс\",\n",
    "        \"без учёта ндс\",\n",
    "        \"ндс не применялся\",\n",
    "        \"ндс не применяется\",\n",
    "        \"не включает ндс\",\n",
    "    ]\n",
    "\n",
    "    # где встречается любое исключение\n",
    "    mask_excl = pd.Series(False, index=df.index)\n",
    "    for ph in exclude_phrases:\n",
    "        mask_excl |= desc.str.contains(re.escape(ph))\n",
    "\n",
    "    # где явно упоминается НДС\n",
    "    mask_nds = desc.str.contains(r\"\\bндс\\b\")\n",
    "\n",
    "    # применять конверсию только если есть НДС и нет исключений\n",
    "    mask_apply = mask_nds & ~mask_excl\n",
    "\n",
    "    # обновляем указанные ценовые столбцы\n",
    "    for col in price_cols:\n",
    "        if col not in df.columns:\n",
    "            continue\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "        df.loc[mask_apply & df[col].notna(), col] = (\n",
    "            df.loc[mask_apply, col] * 0.8\n",
    "        ).round(2)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee750a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df = NDS_conv(\n",
    "    total_df,\n",
    "    \"Описание цены\",\n",
    "    [\"Цена в бел. руб.\", \"Цена в долларах США\", \"Цена в евро\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82eb6cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Цена за площадь\n",
    "total_df[\"Цена в бел. руб. за кв.м\"] = (\n",
    "    total_df[\"Цена в бел. руб.\"] / total_df[\"Общая площадь КС, кв.м\"]\n",
    ")\n",
    "total_df[\"Цена в долларах США за кв.м\"] = (\n",
    "    total_df[\"Цена в долларах США\"] / total_df[\"Общая площадь КС, кв.м\"]\n",
    ")\n",
    "total_df[\"Цена в евро за кв.м\"] = (\n",
    "    total_df[\"Цена в евро\"] / total_df[\"Общая площадь КС, кв.м\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925804b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(total_df.shape)\n",
    "total_df = total_df[\n",
    "    (total_df[\"Переходящая доля\"].isin(not_allowed_fractions))\n",
    "    | (total_df[\"Переходящая доля\"].isna())\n",
    "]\n",
    "print(total_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecff1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df.to_excel(\"./data/clean_df.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b15db25",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df.to_csv(\"./data/clean_full_df.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
