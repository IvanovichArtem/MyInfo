def predict_and_evaluate(df: pd.DataFrame, id_col, dt_col, col, migration_matrix, p=False, view=True):
    df = df.copy()
    df = df.sort_values([id_col, dt_col]).reset_index(drop=True)

    latest_gr = dict(zip(df[id_col], df[col]))
    predicted_values = []

    for index, row in df.iterrows():
        current_id = row[id_col]
        current_state = latest_gr.get(current_id, row[col])
        
        if p:
            next_state = np.random.choice(migration_matrix.columns, 
                                          p=migration_matrix.loc[current_state].values)
        elif current_state in migration_matrix.index:
            next_state = migration_matrix.loc[current_state].idxmax()
        else:
            next_state = current_state

        latest_gr[current_id] = next_state
        predicted_values.append(next_state)

    df[f'predicted_next_{col}'] = predicted_values

    # Суммы и отклонения для "Задолженность"
    if col == "Задолженность" and view:
        actual_sum = df[col].sum()
        predicted_sum = df[f'predicted_next_{col}'].sum()
        error_pct = ((predicted_sum - actual_sum) / actual_sum) * 100 if actual_sum != 0 else 0

        print("\n[Задолженность] Фактическая сумма задолженности:", actual_sum)
        print("[Задолженность] Предсказанная сумма задолженности:", predicted_sum)
        print(f"[Задолженность] Отклонение от фактической суммы: {error_pct:.2f}%")

    # Accuracy и метрики
    target = df[col].shift(-1).dropna()
    predict = df[f"predicted_next_{col}"].iloc[:-1]
    
    accurancy = accuracy_score(target, predict)
    if view:
        print(f"\nAccuracy score {accurancy:.4f}")

    labels = sorted(df[col].dropna().unique())
    conf_mat = confusion_matrix(target, predict, labels=labels)
    conf_df = pd.DataFrame(conf_mat, index=labels, columns=labels)
    if view:
        print("\nConfusion matrix:")
        plt.figure(figsize=(8, 6))
        sns.heatmap(conf_df, annot=True, fmt='d', cmap='Blues', linewidths=0.5)
        plt.xlabel("Предсказано")
        plt.ylabel("Фактическое")
        plt.title("Confusion matrix")
        plt.show()
    
    class_report = classification_report(target, predict, labels=labels, 
                                         zero_division=0, output_dict=not view)
    return class_report
