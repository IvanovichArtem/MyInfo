import numpy as np
from scipy.optimize import least_squares

class AlphaCalibrator:
    def __init__(self, x, nmatrices, r_s_valid):
        """
        x: какие-то дополнительные данные, если нужны
        nmatrices: список матриц (numpy-массивов), построенных на train
        r_s_valid: валидационная матрица (или вектор), с которой сравниваем результат
        """
        self.x = x
        self.nmatrices = nmatrices
        self.r_s_valid = r_s_valid

        # Запоминаем форму каждой матрицы, чтобы корректно "разворачивать" и "сворачивать" альфа-параметры
        self.shapes = [m.shape for m in self.nmatrices]
        # Полное количество элементов (альфа-параметров) во всех матрицах
        self.num_params = sum(m.size for m in self.nmatrices)

    def _unpack_alphas(self, alpha_flat):
        """
        Превращает одномерный вектор alpha_flat в список двумерных (или 1D) массивов
        соответствующих форм (как у матриц в self.nmatrices).
        """
        alphas = []
        idx = 0
        for shape in self.shapes:
            size = np.prod(shape)  # произведение размеров = общее число элементов
            arr = alpha_flat[idx:idx + size].reshape(shape)
            alphas.append(arr)
            idx += size
        return alphas

    def _pack_alphas(self, alpha_list):
        """
        Превращает список альфа-массивов обратно в один вектор для оптимизатора.
        """
        return np.concatenate([a.ravel() for a in alpha_list])

    def _residuals(self, alpha_flat):
        """
        Функция, которую будет минимизировать least_squares.
        Возвращает вектор «остатков», которые нужно занулить или минимизировать.
        """
        # "Разворачиваем" все альфа-параметры
        alphas = self._unpack_alphas(alpha_flat)

        # Для каждой матрицы берём соответствующую "альфу" и возводим матрицу в степень
        preds = []
        for m, a in zip(self.nmatrices, alphas):
            # np.power(m, a) - возводим в вещественную степень поэлементно
            # Если форма m и a совпадают, это поэлементное возведение
            # Если a скаляр, то нужна простая broadcast-логика
            p = np.power(m, a)  
            preds.append(p)

        # Допустим, мы хотим «суммарный» предикт (или средний) – зависит от вашей задачи
        # Если ваша цель – чтобы сумма по всем матрицам как-то соответствовала r_s_valid,
        # то, к примеру, берём сумму по всем preds (или делаем что-то иное по задаче).
        pred_sum = np.sum(preds, axis=0)
        
        # Возвращаем разницу, которую будет минимизировать least_squares
        # (least_squares сводит к нулю вектор, так что это фактически r_s_valid - pred_sum).
        return (pred_sum - self.r_s_valid).ravel()

    def calibrate(self, alpha_init=None, bounds=None):
        """
        Запуск оптимизации. Возвращаем найденные альфа-массивы.
        alpha_init: начальное приближение для всех альф (одномерный numpy массив соответствующего размера)
        bounds: если нужно, кортеж (min_bound, max_bound) в формате, подходящем для least_squares
        """
        if alpha_init is None:
            # Пусть все альфы начнутся с нулей (или единиц) – зависит от задачи
            alpha_init = np.zeros(self.num_params, dtype=float)

        if bounds is None:
            # Можем не ограничивать или поставить что-то вроде (0, np.inf), смотрите по задаче
            # Формат для least_squares: bounds=(lb, ub), где lb и ub – массивы или скаляры
            bounds = (-np.inf, np.inf)

        # Запускаем оптимизацию методом наименьших квадратов
        result = least_squares(self._residuals, alpha_init, bounds=bounds)

        # Сохраняем результат и "раскладываем" альфа-параметры обратно по матрицам
        self.alpha_flat_ = result.x
        self.alphas_ = self._unpack_alphas(result.x)

        # Можем вернуть что-то полезное
        return self.alphas_
